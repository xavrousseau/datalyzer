# ğŸŒ¸ Datalyzer â€“ Analyse exploratoire, nettoyageâ€¦ et SQL Lab (DuckDB)

Datalyzer est une application interactive Streamlit qui transforme vos donnÃ©es tabulaires (CSV, Excel, Parquet) en une expÃ©rience dâ€™exploration fluide, pÃ©dagogique et esthÃ©tique.
Elle guide chaque Ã©tape de lâ€™**analyse exploratoire des donnÃ©es (EDA)** : import, exploration, nettoyage, typage, dÃ©tection dâ€™anomalies, Ã©valuation de la qualitÃ©, analyses multivariÃ©es, **exposition SQL** et export final.

ConÃ§ue pour les **data analysts, data scientists et ingÃ©nieurs data**, Datalyzer associe :

* une **interface intuitive** pour explorer sans coder,
* des **outils robustes** pour fiabiliser les jeux de donnÃ©es,
* des **visualisations interactives** pour comprendre rapidement vos variables et leurs relations,
* un **SQL Lab** (DuckDB en mÃ©moire) pour requÃªter directement les rÃ©sultats intermÃ©diaires.

ğŸ‘‰ **Essayer en ligne** : [https://datalyzer.streamlit.app/](https://datalyzer.streamlit.app/)

---

## FonctionnalitÃ©s principales

* âœ… **Import intelligent** : CSV, TXT, Excel, Parquet (sÃ©parateur auto pour CSV/TXT)
* ğŸ§¬ **Typage automatique et manuel** : dÃ©tection + correction (int, float, bool, date, cat, texte)
* ğŸ” **Exploration guidÃ©e** : stats, manquants, distributions, outliers, corrÃ©lations
* ğŸ§¹ **Nettoyage rapide** : suppression NA, colonnes constantes, faible variance
* ğŸ§ª **QualitÃ© des donnÃ©es** : score sur 100 + drapeaux (NA, doublons, placeholders)
* ğŸš¨ **Anomalies** : mÃ©thodes robustes (Z-score, IQR, MAD)
* ğŸ¯ **Analyse catÃ©gorielle** : CramÃ©râ€™s V, crosstabs normalisÃ©s, barres empilÃ©es, boxplots
* ğŸ“Š **Analyse cible** : corrÃ©lations cible num., groupements par catÃ©gorie
* ğŸ“ˆ **MultivariÃ©e** : ACP (PCA), K-means, variance expliquÃ©e, projections 2D/3D
* ğŸ”— **Jointures intelligentes** : suggestions de clÃ©s, alignement des types, couverture
* ğŸ’¾ **Export avancÃ©** : colonnes + filtres de lignes (ET/OU, top-N, Ã©chantillon, dÃ©dup, NA)
* ğŸ•°ï¸ **Snapshots** : sauvegarde dâ€™Ã©tats intermÃ©diaires
* ğŸ§© **SQL Lab (DuckDB)** : exÃ©cute des **SELECT** sur les tables exposÃ©es depuis nâ€™importe quelle section

---

## SQL Lab (DuckDB) â€” câ€™est quoi ?

Un **moteur SQL en mÃ©moire** pour requÃªter instantanÃ©ment les sorties des diffÃ©rentes sections (typage, anomalies, PCA, agrÃ©gatsâ€¦).
Techniquement :

* **DuckDB** tourne en mÃ©moire et gÃ¨re des vues/tab. Ã  partir de `pandas`, `polars` ou `pyarrow`.

* Un petit pont `utils/sql_bridge.py` te permet dâ€™**exposer** nâ€™importe quel DataFrame au SQL Lab via :

  ```python
  from utils.sql_bridge import expose_to_sql_lab

  expose_to_sql_lab("nom_table", df, make_active=True)
  ```

  * `nom_table` est nettoyÃ© (`-` et espaces â†’ `_`).
  * `make_active=True` (optionnel) marque cette table comme **active** (utile pour autocomplÃ©tion cÃ´tÃ© UI).

* Le module `utils/sql_lab.py` fournit :

  * une **connexion DuckDB** persistante en session,
  * lâ€™**enregistrement** (ou rÃ©-enregistrement) des tables exposÃ©es,
  * une exÃ©cution **sÃ©curisÃ©e** des requÃªtes (seuls les `SELECT` sont autorisÃ©s),
  * lâ€™**introspection** (liste des tables, `DESCRIBE` friendly).

### SÃ©curitÃ© (garde-fous)

Le SQL Lab **refuse** DDL/DML (ex. `DROP`, `UPDATE`, `CREATE`, `ALTER`, `ATTACH`â€¦), seules les requÃªtes **SELECT** sont exÃ©cutÃ©es.
Les tables exposÃ©es sont rÃ©-enregistrÃ©es comme **vues DuckDB** Ã  chaque mise Ã  jour.

### Bonnes pratiques de nommage

Pour garder une cartographie claire, Datalyzer nomme souvent les tables exposÃ©es ainsi :

* `nom_fichier__missing_dropped` â€” aprÃ¨s nettoyage NA
* `nom_fichier__outliers_iqr_<col>` â€” outliers dÃ©tectÃ©s
* `nom_fichier__auto_cleaned` â€” nettoyage auto
* `nom_fichier__pca_scores_<k>[_std]` â€” scores PCA
* `nom_gauche_nom_droite` â€” jointure
* `nom_fichier__export_selection` â€” sÃ©lection exportÃ©e, etc.

---

## AperÃ§us

* Accueil
  ![Import](docs/screenshot_home.png)

* Import et aperÃ§u des donnÃ©es
  ![Import](docs/screenshot_import.png)

* Exploration et corrÃ©lations interactives
  ![Exploration](docs/screenshot_exploration.png)

* Score de qualitÃ© des donnÃ©es
  ![QualitÃ©](docs/screenshot_quality.png)

* Export propre et traÃ§abilitÃ©
  ![Export](docs/screenshot_export.png)

* SQL Lab â€” requÃªte sur rÃ©sultats intermÃ©diaires
  ![SQL Lab](docs/screenshot_sql_lab.png)

---

## Installation et lancement en local

1. DÃ©pendances :

```bash
pip install -r requirements.txt
```

2. Lancer lâ€™application :

```bash
streamlit run app.py
```

3. Ouvrir dans le navigateur :
   [http://localhost:8501](http://localhost:8501)

---

## Utiliser le SQL Lab dans vos sections

Dans **toute section** oÃ¹ vous produisez un DataFrame exploitable, exposez-le :

```python
from utils.sql_bridge import expose_to_sql_lab

# Exemple : aprÃ¨s typage
expose_to_sql_lab("df_typed", df, make_active=True)

# Exemple : scores PCA (avec index pour jointures faciles)
scores_sql = scores.copy()
scores_sql.insert(0, "__index__", scores_sql.index)
expose_to_sql_lab(f"{nom_fichier}__pca_scores_{n_comp}", scores_sql)
```

Ensuite, dans lâ€™onglet **SQL Lab**, requÃªtez librement :

```sql
-- Exemples
SELECT * FROM df_typed LIMIT 50;

SELECT s.__index__, s.PC1, s.PC2, d.cible
FROM myfile__pca_scores_3 AS s
LEFT JOIN df_typed AS d ON d.index = s.__index__;
```

> â„¹ï¸ Lâ€™interface SQL Lab liste les tables disponibles et autorise **uniquement des SELECT**.

---

## Organisation du projet

```
datalyzer/
â”œâ”€â”€ app.py                 # Point dâ€™entrÃ©e Streamlit
â”œâ”€â”€ config.py              # ParamÃ¨tres globaux (thÃ¨me, couleurs, constantes)
â”‚
â”œâ”€â”€ assets/               # Ressources utilisÃ©es par lâ€™app (au runtime)
â”‚   â””â”€â”€ style_dark.css    # Feuille de style custom injectÃ©e dans Streamlit
â”‚
â”œâ”€â”€ sections/              # Pages principales
â”‚   â”œâ”€â”€ home.py            # Page dâ€™accueil
â”‚   â”œâ”€â”€ fichiers.py        # Import CSV/TXT/Excel/Parquet + snapshots
â”‚   â”œâ”€â”€ exploration.py     # Exploration (types, NA, stats, corrÃ©lationsâ€¦)
â”‚   â”œâ”€â”€ typage.py          # DÃ©tection et correction manuelle des types
â”‚   â”œâ”€â”€ suggestions.py     # Colonnes Ã  encoder / vectoriser / exclure
â”‚   â”œâ”€â”€ qualite.py         # Score global de qualitÃ© des donnÃ©es
â”‚   â”œâ”€â”€ anomalies.py       # DÃ©tection dâ€™anomalies (Z-score, IQR, MAD)
â”‚   â”œâ”€â”€ cat_analysis.py    # Analyses catÃ©gorielles (CramÃ©râ€™s V, crosstabsâ€¦)
â”‚   â”œâ”€â”€ cible.py           # Analyse dâ€™une variable cible numÃ©rique
â”‚   â”œâ”€â”€ jointures.py       # Fusion et mÃ©triques de couverture
â”‚   â”œâ”€â”€ multivariee.py     # Analyses multivariÃ©es (ACP, clustering)
â”‚   â”œâ”€â”€  export.py         # Export colonnes + lignes filtrÃ©es
â”‚   â””â”€â”€ sql_lab.py         # interface SQL Lab
â”‚
â”œâ”€â”€ utils/                 # Fonctions transverses
â”‚   â”œâ”€â”€ eda_utils.py       # CorrÃ©lations, CramÃ©râ€™s V, boxplots
â”‚   â”œâ”€â”€ filters.py         # SÃ©lection du dataframe actif + filtres
â”‚   â”œâ”€â”€ log_utils.py       # Journalisation des actions (CSV)
â”‚   â”œâ”€â”€ snapshot_utils.py  # Gestion snapshots (sauvegarde atomique)
â”‚   â”œâ”€â”€ state_manager.py   # Gestion dâ€™Ã©tat Streamlit
â”‚   â”œâ”€â”€ steps.py           # SÃ©quence canonique des Ã©tapes EDA
â”‚   â”œâ”€â”€ sql_lab.py         # Connexion DuckDB, enregistrement, exÃ©cution sÃ©curisÃ©e
â”‚   â””â”€â”€ sql_bridge.py      # Helper "expose_to_sql_lab(name, df, make_active=False)"
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ snapshots/         # Sauvegardes intermÃ©diaires (.csv[.gz])
â”‚   â””â”€â”€ exports/           # DonnÃ©es exportÃ©es
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ history_log.csv    # Historique structurÃ© des actions utilisateur
â”‚
â”œâ”€â”€ images/                # Illustrations (headers, icÃ´nes)
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ README.md              # Documentation
```
---

## Pourquoi utiliser Datalyzer ?

* Disponible en **ligne** : [datalyzer.streamlit.app](https://datalyzer.streamlit.app/)
* Fonctionne aussi **100 % localement**
* UI **claire et pÃ©dagogique**
* **TraÃ§abilitÃ©** : snapshots + logs
* **Modulaire** : facile dâ€™ajouter de nouveaux blocs analytiques
* DÃ©sormais : **requÃªtes SQL instantanÃ©es** sur vos rÃ©sultats intermÃ©diaires

---

## Cas dâ€™usage concrets

* **ContrÃ´le qualitÃ© avant reporting** : vÃ©rifier un export CRM/ERP, dÃ©tecter doublons/placeholders, requÃªter les rÃ©sultats par SQL.
* **PrÃ©paration ML** : corriger les types, encoder, nettoyer â†’ exposer les tables dâ€™entraÃ®nement/validation au SQL Lab.
* **Fusion de fichiers** : joignez plusieurs CSV/Excel, mesurez la couverture, **inspectez la fusion** en SQL.
* **Audit de migration** : score de qualitÃ© + anomalies + requÃªtes ciblÃ©es.
* **Exploration pÃ©dagogique** : interface guidÃ©e + SQL pour illustrer les jointures/agrÃ©gats.

---

## Auteur

Projet conÃ§u et dÃ©veloppÃ© par **Xavier Rousseau**
ğŸ“Š Data Analyst â€” passionnÃ© par la qualitÃ© des donnÃ©es, la visualisation et lâ€™automatisation

---
