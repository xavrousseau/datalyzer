# =============================================================================
# üì¶ IMPORTATION DES LIBRAIRIES
# =============================================================================

import streamlit as st       # Pour cr√©er l'application web interactive
import pandas as pd          # Pour la manipulation de donn√©es
import plotly.express as px  # Pour les visualisations interactives
import numpy as np
from scipy.stats import zscore
import csv                   # Pour la d√©tection du s√©parateur dans les CSV/TXT
from io import StringIO, BytesIO  # Pour manipuler les flux de donn√©es

import sys                   # Pour les interactions syst√®me (ex: monitoring)
import psutil                # Pour l'analyse de la m√©moire

# Importation des fonctions utilitaires pour l'EDA
from eda_utils import (
    detect_variable_types,         # D√©tecte les types de variables
    compute_correlation_matrix,    # Calcule la matrice de corr√©lation
    detect_outliers_iqr,           # D√©tecte les outliers via la m√©thode IQR
    detect_constant_columns,       # D√©tecte les colonnes constantes
    detect_low_variance_columns,   # D√©tecte les colonnes √† faible variance
    encode_categorical,            # Encodage des variables cat√©gorielles (OneHot ou Ordinal)
    plot_missing_values,           # Trace le graphique des valeurs manquantes
    get_columns_above_threshold,   # Liste les colonnes avec un taux de NA sup√©rieur au seuil
    drop_missing_columns           # Supprime les colonnes trop incompl√®tes
)

# Importation d'une fonction pour enregistrer les transformations appliqu√©es
from log_utils import log_transformation

# =============================================================================
# üé® CONFIGURATION GLOBALE DE L‚ÄôAPP
# =============================================================================

st.set_page_config(
    page_title="EDA Explorer ‚Äì Analyse exploratoire de donn√©es",
    layout="wide"
)

# Insertion de styles CSS personnalis√©s pour les √©l√©ments de l'application
st.markdown("""
    <style>
        .stButton>button {
            color: white;
            background: #0099cc;
        }
        .stDownloadButton>button {
            background-color: #28a745;
            color: white;
        }
        .stSlider>div {
            background-color: #f0f0f5;
        }
    </style>
""", unsafe_allow_html=True)

# =============================================================================
# üß≠ BARRE DE NAVIGATION
# =============================================================================

# Menu lat√©ral pour naviguer entre les sections de l'application
section = st.sidebar.radio("üß≠ Navigation", [
    "üìÇ Chargement",
    "üîç Analyse exploratoire",
    "üìä Analyse cat√©gorielle",
    "üéØ Analyse variable cible",
    "üíæ Export"
])

# Initialisation des variables globales : le DataFrame et le fichier upload√©
# Affiche un avertissement global si aucun fichier n'est charg√©
uploaded_file = st.session_state.get("uploaded_file")

if section != "üìÇ Chargement" and uploaded_file is None:
    st.warning("üìÇ Veuillez d‚Äôabord charger un fichier via la section 'üìÇ Chargement'.")
    st.stop()
# =============================================================================
# üìÇ 1. Chargement du fichier (Accueil)
# =============================================================================

if section == "üìÇ Chargement":
    st.title("üìä EDA Explorer ‚Äì Application d'analyse exploratoire de donn√©es")
    st.markdown("---")

    st.subheader("üìÇ Chargement du fichier")
    st.info("üì¶ Vous pouvez importer un fichier jusqu‚Äô√† **200 Mo** (formats support√©s : CSV, TXT, JSON, XLSX, Parquet).")

    # Composant d‚Äôupload
    uploaded_file = st.file_uploader("Choisissez un fichier", type=["csv", "txt", "json", "xlsx", "parquet"])

    if uploaded_file:
        # Sauvegarde du fichier upload√© dans la session pour les prochaines sections
        st.session_state["uploaded_file"] = uploaded_file
        file_extension = uploaded_file.name.split(".")[-1].lower()
        st.info(f"üìÑ Fichier s√©lectionn√© : `{uploaded_file.name}`")

        try:
            # Pour √©viter les probl√®mes li√©s √† la position du curseur, on se replace au d√©but
            uploaded_file.seek(0)
            if file_extension in ["csv", "txt"]:
                raw_text = uploaded_file.read().decode("utf-8", errors="ignore")
                # D√©tection automatique du s√©parateur gr√¢ce √† csv.Sniffer
                detected_sep = csv.Sniffer().sniff(raw_text[:2048]).delimiter
                st.success(f"‚úÖ S√©parateur d√©tect√© automatiquement : `{detected_sep}`")
                df = pd.read_csv(StringIO(raw_text), sep=detected_sep)

            elif file_extension == "json":
                uploaded_file.seek(0)
                df = pd.read_json(uploaded_file)

            elif file_extension == "xlsx":
                df = pd.read_excel(uploaded_file)

            elif file_extension == "parquet":
                df = pd.read_parquet(uploaded_file)

        except Exception as e:
            st.error(f"‚ùå Erreur de lecture : {e}")

        # Aper√ßu si tout s‚Äôest bien pass√©
        if df is not None:
            st.success("‚úÖ Fichier charg√© avec succ√®s.")
            # Sauvegarde du DataFrame dans la session pour √©viter de le recharger
            st.session_state.df = df
            max_rows = st.radio("Nombre de lignes √† afficher :", [5, 10, 20, 50, 100], horizontal=True)
            col1, col2 = st.columns(2)
            col1.metric("Lignes", f"{df.shape[0]:,}".replace(",", "‚ÄØ"))
            col2.metric("Colonnes", f"{df.shape[1]:,}".replace(",", "‚ÄØ"))
            st.dataframe(df.head(max_rows), use_container_width=True)

# =============================================================================
# üîç 2. Analyse exploratoire (EDA)
# =============================================================================

elif section == "üîç Analyse exploratoire" and uploaded_file:
    # R√©cup√©ration du DataFrame depuis la session si d√©j√† charg√©,
    # sinon on le recharge √† partir du fichier upload√©.
    if "df" not in st.session_state:
        uploaded_file.seek(0)  # Remise √† z√©ro du curseur pour une lecture correcte
        file_extension = uploaded_file.name.split(".")[-1].lower()
        if file_extension in ["csv", "txt"]:
            raw_text = uploaded_file.read().decode("utf-8", errors="ignore")
            sep = csv.Sniffer().sniff(raw_text[:2048]).delimiter
            df = pd.read_csv(StringIO(raw_text), sep=sep)
        elif file_extension == "json":
            uploaded_file.seek(0)
            df = pd.read_json(uploaded_file)
        elif file_extension == "xlsx":
            df = pd.read_excel(uploaded_file)
        elif file_extension == "parquet":
            df = pd.read_parquet(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("üîç Analyse exploratoire")
    # Cr√©ation des onglets pour organiser les analyses
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "üìå Types de variables",
        "üìâ Valeurs manquantes",
        "üìà Histogrammes",
        "üö® Outliers",
        "üßπ Nettoyage auto",
        "üßº Nettoyage manuel",
        "üìê Stats descriptives",
        "üß¨ Corr√©lations avanc√©es"
    ])
    # -------------------------------------------------------------------------
    # Onglet 1 : Types de variables
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### üìå Types de variables d√©tect√©es")
        st.info("Aper√ßu des colonnes avec type d√©tect√©, nombre de valeurs uniques, valeurs manquantes et exemple.")
        summary = pd.DataFrame({
            "Nom de la colonne": df.columns,
            "Type pandas": df.dtypes.astype(str),
            "Nb valeurs uniques": df.nunique(),
            "% valeurs manquantes": (df.isna().mean() * 100).round(1).astype(str) + "‚ÄØ%",
            "Exemple de valeur": [
                df[col].dropna().astype(str).unique()[0] if df[col].dropna().shape[0] > 0 else "‚Äî"
                for col in df.columns
            ]
        }).sort_values("Type pandas")
        st.dataframe(summary, use_container_width=True, height=500)

    # -------------------------------------------------------------------------
    # Onglet 2 : Valeurs manquantes
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### üìâ Analyse des valeurs manquantes")
        seuil_pct = st.slider("üõ†Ô∏è Seuil (%) de valeurs manquantes", 0, 100, 20)
        seuil = seuil_pct / 100
        top_n = st.slider("üìå Top colonnes √† afficher", 5, 50, 15)

        fig = plot_missing_values(df, seuil=seuil, top_n=top_n)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("‚úÖ Aucune valeur manquante.")

        cols_to_remove = get_columns_above_threshold(df, seuil=seuil)
        if cols_to_remove:
            st.warning(f"{len(cols_to_remove)} colonnes d√©passent {seuil_pct}% de valeurs manquantes.")
            st.code(", ".join(cols_to_remove))

            if st.checkbox("‚ùå Supprimer ces colonnes"):
                df, dropped = drop_missing_columns(df, seuil=seuil)
                log_transformation(f"{len(dropped)} colonnes supprim√©es pour seuil {seuil_pct}%")
                st.success(f"{len(dropped)} colonnes supprim√©es.")
                st.session_state.df = df

    # -------------------------------------------------------------------------
    # Onglet 3 : Histogrammes des variables num√©riques
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### üìà Distribution des variables num√©riques")
        num_cols = df.select_dtypes(include=["number"]).columns.tolist()
        if not num_cols:
            st.warning("‚ö†Ô∏è Aucune variable num√©rique d√©tect√©e.")
        else:
            selected_num = st.selectbox("üìä Choisissez une variable", num_cols)
            st.plotly_chart(px.histogram(df, x=selected_num), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : D√©tection d'outliers (m√©thode IQR)
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### üö® D√©tection d'outliers (m√©thode IQR)")
        num_cols = df.select_dtypes(include=["number"]).columns.tolist()
        col = st.selectbox("Variable √† analyser", num_cols, key="iqr_col")
        outliers = detect_outliers_iqr(df, col)
        st.write(f"üîç {len(outliers)} outliers d√©tect√©s.")
        st.dataframe(outliers)

    # -------------------------------------------------------------------------
    # Onglet 5 : Suggestions automatiques de nettoyage
    # -------------------------------------------------------------------------
    with tab5:
        st.markdown("### üßπ Suggestions automatiques de nettoyage")
        st.info("Colonnes constantes, faible variance ou fortement manquantes.")
        st.write("üî∏ Colonnes constantes :", detect_constant_columns(df))
        st.write("üî∏ Faible variance :", detect_low_variance_columns(df))
        missing = df.isnull().mean().sort_values(ascending=False)
        st.write("üî∏ Valeurs manquantes :", missing[missing > 0])

    # -------------------------------------------------------------------------
    # Onglet 6 : Nettoyage manuel
    # -------------------------------------------------------------------------
    with tab6:
        st.markdown("### üßº Nettoyage manuel")
        if st.button("üîÅ Supprimer les doublons"):
            initial_len = len(df)
            df = df.drop_duplicates()
            removed = initial_len - len(df)
            st.session_state.df = df
            log_transformation(f"{removed} doublons supprim√©s.")
            st.success(f"{removed} doublons supprim√©s.")

        cols_to_drop = st.multiselect("Colonnes √† supprimer", df.columns.tolist())
        if cols_to_drop and st.button("üóëÔ∏è Supprimer les colonnes s√©lectionn√©es"):
            df.drop(columns=cols_to_drop, inplace=True)
            log_transformation(f"Colonnes supprim√©es manuellement : {', '.join(cols_to_drop)}")
            st.session_state.df = df
            st.success("Colonnes supprim√©es.")

    # -------------------------------------------------------------------------
    # Onglet 7 : Statistiques descriptives avanc√©es
    # -------------------------------------------------------------------------
    with tab7:
        st.markdown("### üìê Statistiques descriptives avanc√©es")

        st.info("Affiche les statistiques classiques (moyenne, √©cart-type‚Ä¶) et avanc√©es (skewness, kurtosis).")

        # Colonnes num√©riques d√©tect√©es automatiquement
        num_cols = df.select_dtypes(include="number").columns.tolist()

        if not num_cols:
            st.warning("‚ö†Ô∏è Aucune variable num√©rique d√©tect√©e.")
            st.stop()

        # Option : analyse group√©e par une variable cat√©gorielle
        group_by = st.selectbox("üîÅ Grouper par (optionnel)", [None] + df.select_dtypes(include=["object", "category"]).columns.tolist())

        if group_by:
            # Calcul des statistiques group√©es
            desc_stats = df.groupby(group_by)[num_cols].agg(["mean", "median", "std", "min", "max", "skew", "kurt"])
            # Aplatir les colonnes multi-index
            desc_stats.columns = ['_'.join(col).strip() for col in desc_stats.columns.values]
            st.dataframe(desc_stats, use_container_width=True)
        else:
            # Statistiques globales sur les colonnes num√©riques
            desc_stats = df[num_cols].agg(["mean", "median", "std", "min", "max", "skew", "kurt"]).T
            desc_stats.columns = ["Moyenne", "M√©diane", "√âcart-type", "Min", "Max", "Skewness", "Kurtosis"]
            st.dataframe(desc_stats, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 8 : Corr√©lation avanc√©e
    # -------------------------------------------------------------------------
    with tab8:
        st.markdown("### üß¨ Corr√©lation avanc√©e entre variables num√©riques")
        st.info("üìå Analyse des d√©pendances lin√©aires et non-lin√©aires entre variables num√©riques.")

        # S√©lection du type de corr√©lation √† afficher
        method = st.radio("üìê M√©thode de corr√©lation :", ["pearson", "spearman", "kendall"], horizontal=True)

        # Slider pour appliquer un seuil minimal d'affichage
        threshold = st.slider("üéöÔ∏è Seuil de corr√©lation absolue minimale", 0.0, 1.0, 0.3, 0.05)

        # S√©lection des colonnes num√©riques uniquement
        numeric_cols = df.select_dtypes(include=["number"]).columns

        if len(numeric_cols) < 2:
            st.warning("‚ö†Ô∏è Pas assez de variables num√©riques pour afficher une matrice de corr√©lation.")
        else:
            # Calcul de la matrice de corr√©lation avec la m√©thode choisie
            corr_matrix = df[numeric_cols].corr(method=method)

            # Cr√©ation d'une version aplatie de la matrice (utile pour filtrer)
            corr_pairs = (
                corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
                .stack()
                .reset_index()
            )
            corr_pairs.columns = ["Variable 1", "Variable 2", "Corr√©lation"]

            # Filtrage selon le seuil choisi
            filtered_corr = corr_pairs[abs(corr_pairs["Corr√©lation"]) >= threshold]
            filtered_corr = filtered_corr.sort_values("Corr√©lation", ascending=False)

            st.markdown("#### üìã Paires de variables corr√©l√©es")
            st.dataframe(filtered_corr, use_container_width=True)

            # Heatmap interactive (optionnelle)
            st.markdown("#### üå°Ô∏è Heatmap de la matrice de corr√©lation")
            fig = px.imshow(
                corr_matrix,
                text_auto=".2f",
                color_continuous_scale="RdBu_r",
                zmin=-1,
                zmax=1,
                aspect="auto",
                title=f"Matrice de corr√©lation ({method})"
            )
            st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# üìä 3. Analyse des variables cat√©gorielles
# =============================================================================

elif section == "üìä Analyse cat√©gorielle" and uploaded_file:
    # Chargement du DataFrame
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("üìä Analyse des variables cat√©gorielles")

    # D√©tection automatique des colonnes cat√©gorielles
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    if not cat_cols:
        st.warning("‚ö†Ô∏è Aucune variable cat√©gorielle d√©tect√©e dans le dataset.")
        st.stop()

    # Cr√©ation des onglets
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìã Aper√ßu global",
        "üìä Barplots",
        "üìà Fr√©quences cumul√©es",
        "üí° Suggestions d'encodage"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 : Aper√ßu global des colonnes cat√©gorielles
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### üìã D√©tail des variables cat√©gorielles")
        st.info("Nombre de modalit√©s uniques, modalit√© la plus fr√©quente et taux de valeurs manquantes.")

        summary_cat = pd.DataFrame({
            "Colonne": cat_cols,
            "Nb modalit√©s uniques": [df[col].nunique() for col in cat_cols],
            "Modalit√© la + fr√©quente": [df[col].mode()[0] if not df[col].mode().empty else "‚Äî" for col in cat_cols],
            "Valeurs manquantes (%)": [f"{df[col].isna().mean() * 100:.1f} %" for col in cat_cols]
        })

        st.dataframe(summary_cat, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 2 : Barplots des top modalit√©s
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### üìä Distribution des modalit√©s (Top N)")
        selected_col = st.selectbox("üìå Choisissez une variable cat√©gorielle", cat_cols, key="cat_barplot")
        top_n = st.slider("üî¢ Nombre de modalit√©s √† afficher", 3, 30, 10)

        top_modalities = (
            df[selected_col]
            .value_counts()
            .head(top_n)
            .reset_index()
        )
        top_modalities.columns = ["Modalit√©", "Fr√©quence"]

        fig = px.bar(
            top_modalities,
            x="Modalit√©",
            y="Fr√©quence",
            title=f"Top {top_n} modalit√©s ‚Äì {selected_col}",
            text="Fr√©quence"
        )
        st.plotly_chart(fig, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 : Fr√©quences relatives et cumul√©es
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### üìà Fr√©quences relatives et cumul√©es")
        selected_col = st.selectbox("üìä Variable cat√©gorielle √† analyser", cat_cols, key="cat_freq")

        # Calcul des fr√©quences relatives
        freq_df = df[selected_col].value_counts(normalize=True).reset_index()

        # Renommage des colonnes pour correspondre √† celles appel√©es ensuite
        freq_df.columns = ["Modalit√©", "Fr√©quence"]

        # Calcul des fr√©quences cumul√©es
        freq_df["Fr√©quence cumul√©e"] = freq_df["Fr√©quence"].cumsum()
        freq_df["% Fr√©quence"] = (freq_df["Fr√©quence"] * 100).round(2).astype(str) + " %"
        freq_df["% Cumul√©e"] = (freq_df["Fr√©quence cumul√©e"] * 100).round(2).astype(str) + " %"

        # Affichage du tableau final avec les bonnes colonnes
        st.dataframe(freq_df[["Modalit√©", "% Fr√©quence", "% Cumul√©e"]], use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : Suggestions d‚Äôencodage selon la cardinalit√©
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### üí° Suggestions d'encodage automatique")
        st.info("Encodage recommand√© en fonction du nombre de modalit√©s uniques par colonne.")

        seuil_card = st.slider("üîß Seuil max pour OneHot encoding (nb modalit√©s)", 2, 50, 10)

        suggestions = []
        for col in cat_cols:
            nb_modal = df[col].nunique()
            if nb_modal <= seuil_card:
                suggestion = "OneHot"
            elif nb_modal == 2:
                suggestion = "Binaire"
            elif nb_modal > seuil_card:
                suggestion = "Ordinal / Embedding"
            else:
                suggestion = "√Ä v√©rifier"

            suggestions.append((col, nb_modal, suggestion))

        suggestion_df = pd.DataFrame(suggestions, columns=["Colonne", "Nb modalit√©s", "Encodage sugg√©r√©"])
        st.dataframe(suggestion_df.sort_values("Nb modalit√©s"), use_container_width=True)

# =============================================================================
# üö® 4. D√©tection de probl√®mes de qualit√© de donn√©es
# =============================================================================

elif section == "üö® Qualit√© des donn√©es" and uploaded_file:
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("üö® Probl√®mes potentiels de qualit√© des donn√©es")

    # -------------------------------------------------------------------------
    st.markdown("### üîç Colonnes mal typ√©es")
    suspect_numeric_as_str = [
        col for col in df.select_dtypes(include="object")
        if df[col].str.replace(".", "", regex=False).str.replace(",", "", regex=False).str.isnumeric().mean() > 0.8
    ]
    if suspect_numeric_as_str:
        st.warning(f"üìå Ces colonnes semblent contenir des valeurs num√©riques mais sont typ√©es comme 'object' :")
        st.code(", ".join(suspect_numeric_as_str))
    else:
        st.success("‚úÖ Aucun champ suspect d√©tect√© parmi les variables 'object'.")

    # -------------------------------------------------------------------------
    st.markdown("### üìõ Noms suspects ou non normalis√©s")
    suspect_names = [col for col in df.columns if col.startswith("Unnamed") or "id" in col.lower()]
    if suspect_names:
        st.warning("‚ö†Ô∏è Colonnes avec noms suspects :")
        st.code(", ".join(suspect_names))
    else:
        st.success("‚úÖ Aucun nom de colonne suspect d√©tect√©.")

    # -------------------------------------------------------------------------
    st.markdown("### üß© Valeurs suspectes ou placeholders")
    placeholder_values = ["unknown", "n/a", "na", "undefined", "None", "missing", "?"]
    placeholder_hits = {}
    for col in df.columns:
        hits = df[col].astype(str).str.lower().isin(placeholder_values).sum()
        if hits > 0:
            placeholder_hits[col] = hits
    if placeholder_hits:
        st.warning("üîç Valeurs suspectes trouv√©es (placeholders) :")
        st.write(pd.DataFrame.from_dict(placeholder_hits, orient="index", columns=["Occurrences"]))
    else:
        st.success("‚úÖ Aucune valeur placeholder d√©tect√©e.")

    # -------------------------------------------------------------------------
    st.markdown("### üß™ Valeurs extr√™mes (Z-score simplifi√©)")
    import numpy as np
    from scipy.stats import zscore

    num_cols = df.select_dtypes(include="number").columns
    z_outlier_summary = {}
    for col in num_cols:
        if df[col].dropna().std() == 0:
            continue
        z_scores = np.abs(zscore(df[col].dropna()))
        outliers = (z_scores > 3).sum()
        if outliers > 0:
            z_outlier_summary[col] = outliers
    if z_outlier_summary:
        st.warning("üö® Valeurs extr√™mes d√©tect√©es (Z-score > 3) :")
        st.write(pd.DataFrame.from_dict(z_outlier_summary, orient="index", columns=["Nb outliers"]))
    else:
        st.success("‚úÖ Pas de valeurs extr√™mes d√©tect√©es via Z-score.")

    # -------------------------------------------------------------------------
    st.markdown("### üìå Colonnes uniques / constantes")
    const_cols = detect_constant_columns(df)
    if const_cols:
        st.warning(f"‚ö†Ô∏è Colonnes constantes d√©tect√©es ({len(const_cols)}) :")
        st.code(", ".join(const_cols))
    else:
        st.success("‚úÖ Aucune colonne constante d√©tect√©e.")

# =============================================================================
# üß™ 5. Analyse multivari√©e et interactions
# =============================================================================

elif section == "üß™ Analyse multivari√©e" and uploaded_file:
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("üß™ Analyse multivari√©e et interactions")

    # S√©paration des types de variables
    num_cols = df.select_dtypes(include="number").columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    tab1, tab2, tab3 = st.tabs([
        "üìâ ACP (PCA)",
        "üìä Interactions num ‚Üî cat",
        "üìö Corr√©lation cat√©gorielle"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 ‚Äì ACP sur les variables num√©riques
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### üìâ Analyse en Composantes Principales (ACP / PCA)")
        st.info("Permet de r√©duire les dimensions tout en conservant un maximum d'information.")

        if len(num_cols) < 2:
            st.warning("‚ö†Ô∏è Pas assez de variables num√©riques pour l'ACP.")
        else:
            from sklearn.preprocessing import StandardScaler
            from sklearn.decomposition import PCA
            import plotly.express as px

            df_scaled = StandardScaler().fit_transform(df[num_cols].dropna())

            n_comp = st.slider("Nombre de composantes", 2, min(10, len(num_cols)), 2)
            pca = PCA(n_components=n_comp)
            components = pca.fit_transform(df_scaled)

            pca_df = pd.DataFrame(components, columns=[f"PC{i+1}" for i in range(n_comp)])

            # Option de colorisation par cat√©gorie
            color_cat = st.selectbox("Colorer par (optionnel)", [None] + cat_cols)
            if color_cat:
                pca_df[color_cat] = df[cat_cols][color_cat]

            # Graphique 2D
            st.markdown("#### üåà Projection des donn√©es (PC1 vs PC2)")
            fig = px.scatter(pca_df, x="PC1", y="PC2", color=color_cat if color_cat else None)
            st.plotly_chart(fig, use_container_width=True)

            # Variance expliqu√©e
            explained = pd.DataFrame({
                "Composante": [f"PC{i+1}" for i in range(len(pca.explained_variance_ratio_))],
                "Variance expliqu√©e (%)": (pca.explained_variance_ratio_ * 100).round(2)
            })
            st.markdown("#### üìà Variance expliqu√©e par composante")
            st.dataframe(explained)

    # -------------------------------------------------------------------------
    # Onglet 2 ‚Äì Num ‚Üî Cat : boxplot et swarmplot
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### üßÆ Analyse crois√©e num√©rique / cat√©gorielle")

        if not cat_cols or not num_cols:
            st.warning("‚ö†Ô∏è Il faut au moins une variable cat√©gorielle et une num√©rique.")
        else:
            cat_var = st.selectbox("Variable cat√©gorielle", cat_cols, key="cat_group")
            num_var = st.selectbox("Variable num√©rique", num_cols, key="num_group")

            st.plotly_chart(px.box(df, x=cat_var, y=num_var, title="Boxplot crois√©"), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 ‚Äì Corr√©lations entre variables cat√©gorielles
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### üìö Corr√©lations entre variables cat√©gorielles (Cram√©r's V)")
        st.info("Mesure la force de l'association entre deux variables cat√©gorielles.")

        if len(cat_cols) < 2:
            st.warning("‚ö†Ô∏è Pas assez de colonnes cat√©gorielles pour le calcul de Cram√©r's V.")
        else:
            import numpy as np
            import seaborn as sns
            import matplotlib.pyplot as plt
            from scipy.stats import chi2_contingency

            def cramers_v(x, y):
                confusion_matrix = pd.crosstab(x, y)
                chi2 = chi2_contingency(confusion_matrix)[0]
                n = confusion_matrix.sum().sum()
                phi2 = chi2 / n
                r, k = confusion_matrix.shape
                phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))
                rcorr = r - ((r-1)**2)/(n-1)
                kcorr = k - ((k-1)**2)/(n-1)
                return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))

            matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)
            for col1 in cat_cols:
                for col2 in cat_cols:
                    if col1 == col2:
                        matrix.loc[col1, col2] = 1.0
                    else:
                        matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])
            matrix = matrix.astype(float)

            st.markdown("#### üî• Matrice de Cram√©r's V")
            fig = px.imshow(matrix, text_auto=".2f", aspect="auto", color_continuous_scale="OrRd")
            st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# üéØ 6. Analyse orient√©e cible
# =============================================================================

elif section == "üéØ Analyse variable cible" and uploaded_file:
    # On r√©cup√®re le DataFrame nettoy√© depuis la session s'il existe, sinon on le recharge.
    if "df" not in st.session_state:
        # ATTENTION‚ÄØ: ici, le chargement est simplifi√© pour un fichier CSV.
        # Pour d'autres formats, il faut adapter la lecture (cf. section Chargement).
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("üéØ Analyse orient√©e variable cible")

    # D√©tection des variables num√©riques et cat√©gorielles
    num_cols = df.select_dtypes(include=["number"]).columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    if not num_cols:
        st.warning("‚ö†Ô∏è Aucune variable num√©rique d√©tect√©e.")
        st.stop()

    # S√©lection de la variable cible principale et optionnelle
    target_1 = st.selectbox("üéØ Variable cible principale", num_cols, key="target1")
    target_2 = st.selectbox("üéØ Variable cible secondaire (optionnel)", [None] + num_cols, key="target2")

    # Cr√©ation des onglets pour l'analyse de la variable cible
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Corr√©lations",
        "üìà Cible par groupe",
        "üì¶ Boxplot",
        "üßÆ Nuage de points"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 : Corr√©lations
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### üìä Corr√©lations avec la variable cible")
        st.info("Corr√©lations lin√©aires (Pearson) avec la variable cible principale.")
        corr = df.select_dtypes(include=["number"]).corr()[target_1].drop(target_1).sort_values(ascending=False)
        st.dataframe(corr)
        st.plotly_chart(px.bar(corr.reset_index(), x="index", y=target_1), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 2 : Analyse de la cible par groupe
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### üìà Moyenne de la cible par groupe")
        group_col = st.selectbox("Variable cat√©gorielle", cat_cols, key="groupcol")
        avg_target1 = df.groupby(group_col)[target_1].mean().sort_values(ascending=False).reset_index()
        st.plotly_chart(px.bar(avg_target1, x=group_col, y=target_1), use_container_width=True)

        if target_2:
            avg_target2 = df.groupby(group_col)[target_2].mean().sort_values(ascending=False).reset_index()
            st.plotly_chart(px.bar(avg_target2, x=group_col, y=target_2), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 : Boxplot interactif
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### üì¶ Boxplot interactif")
        cat_col = st.selectbox("X = variable cat√©gorielle", cat_cols, key="box_cat")
        num_col = st.selectbox("Y = variable num√©rique", num_cols, key="box_num")
        st.plotly_chart(px.box(df, x=cat_col, y=num_col), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : Scatter Plot (nuage de points)
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### üßÆ Scatter Plot")
        x = st.selectbox("X", num_cols, key="xscatter")
        y = st.selectbox("Y", num_cols, key="yscatter")
        color = st.selectbox("Couleur (optionnelle)", [None] + cat_cols, key="color_scatter")
        st.plotly_chart(px.scatter(df, x=x, y=y, color=color), use_container_width=True)

# =============================================================================
# üíæ 4. Export
# =============================================================================

elif section == "üíæ Export" and uploaded_file:
    # R√©cup√©ration du DataFrame nettoy√© depuis la session
    df = st.session_state.get("df")
    if df is not None:
        st.subheader("üíæ Export du fichier final")
        with st.form("export_form"):
            file_name = st.text_input("Nom du fichier CSV", value="cleaned_data.csv")
            submit = st.form_submit_button("üì• T√©l√©charger")
            if submit:
                csv_data = df.to_csv(index=False).encode("utf-8")
                st.download_button("T√©l√©charger le CSV", csv_data, file_name, mime="text/csv")
    else:
        st.warning("‚ùå Aucune donn√©e disponible pour l‚Äôexport.")
