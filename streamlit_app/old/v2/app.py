# =============================================================================
# üì¶ IMPORTATION DES LIBRAIRIES
# =============================================================================

# Importation de Streamlit : permet de cr√©er des applications web interactives en Python
import streamlit as st  

# Importation de Pandas : fournit des structures de donn√©es et des outils d'analyse (DataFrame, etc.)
import pandas as pd  

# Importation de Plotly Express : utilis√© pour cr√©er des graphiques interactifs facilement (histogrammes, boxplots, etc.)
import plotly.express as px  

# Importation de fonctions personnalis√©es pour l'analyse exploratoire (EDA) depuis le fichier eda_utils.py
from eda_utils import (
    detect_variable_types,         # Fonction pour d√©tecter automatiquement le type de chaque colonne (num√©rique, cat√©gorielle, etc.)
    compute_correlation_matrix,    # Fonction pour calculer la matrice de corr√©lation entre les variables num√©riques
    detect_outliers_iqr,           # Fonction pour d√©tecter les valeurs aberrantes (outliers) √† l'aide de la m√©thode IQR (Interquartile Range)
    detect_constant_columns,       # Fonction pour identifier les colonnes ayant une seule valeur (constantes)
    detect_low_variance_columns,   # Fonction pour identifier les colonnes ayant une variance tr√®s faible
    encode_categorical,            # Fonction pour encoder les variables cat√©gorielles en utilisant des m√©thodes comme OneHot ou Ordinal encoding
    plot_missing_values,           # Fonction pour g√©n√©rer un graphique interactif affichant les valeurs manquantes
    get_columns_above_threshold,   # Fonction pour obtenir les colonnes dont le taux de valeurs manquantes d√©passe un seuil d√©fini
    drop_missing_columns           # Fonction pour supprimer les colonnes trop incompl√®tes (taux de valeurs manquantes √©lev√©)
)

# Importation d'une fonction personnalis√©e pour enregistrer les transformations dans un log
from log_utils import log_transformation  # Permet de suivre et enregistrer les modifications apport√©es aux donn√©es
 


import csv
from io import StringIO, BytesIO
import sys
import psutil
 

# =============================================================================
# üé® CONFIGURATION DE LA PAGE ET STYLE
# =============================================================================

# Configuration de la page Streamlit : titre de l'onglet et mise en page
st.set_page_config(page_title="EDA Explorer", layout="wide")

# Insertion de styles CSS personnalis√©s pour am√©liorer l'apparence des composants (boutons, sliders, etc.)
st.markdown("""
    <style>
        /* Personnalisation du style des boutons de Streamlit */
        .stButton>button {
            color: white;
            background: #0099cc;
        }
        /* Personnalisation du style des boutons de t√©l√©chargement */
        .stDownloadButton>button {
            background-color: #28a745;
            color: white;
        }
        /* Personnalisation du style des sliders */
        .stSlider>div {
            background-color: #f0f0f5;
        }
    </style>
""", unsafe_allow_html=True)

# Affichage du titre principal de l'application sur la page
st.title("üìä EDA Explorer ‚Äì Application d'analyse exploratoire de donn√©es")
# S√©parateur horizontal pour organiser visuellement la page
st.markdown("---")
 
# =============================================================================
# üìÇ 1. Chargement du fichier (via upload uniquement)
# =============================================================================

# Titre de la section
st.markdown("### üìÇ 1. Chargement du fichier")

# üìå Message sur la limite de taille impos√©e par Streamlit
st.info("üì¶ Vous pouvez importer un fichier jusqu‚Äô√† **200 Mo** "
        "(formats support√©s : CSV, TXT, JSON, XLSX, Parquet).")

# üì§ Composant Streamlit pour uploader un fichier
uploaded_file = st.file_uploader(
    "Choisissez un fichier de donn√©es",
    type=["csv", "txt", "json", "xlsx", "parquet"]
)

# Initialisation du DataFrame
df = None

# Si un fichier est upload√© :
if uploaded_file is not None:
    # Extraction de l‚Äôextension du fichier
    file_extension = uploaded_file.name.split(".")[-1].lower()
    st.info(f"üìÑ Fichier s√©lectionn√© : `{uploaded_file.name}`")

    # ‚¨áÔ∏è Chargement des fichiers CSV ou TXT
    if file_extension in ["csv", "txt"]:
        try:
            # Lecture du fichier brut
            raw_text = uploaded_file.read().decode("utf-8", errors="ignore")

            # D√©tection automatique du s√©parateur
            sniffer = csv.Sniffer()
            detected_sep = sniffer.sniff(raw_text[:2048]).delimiter
            st.success(f"‚úÖ S√©parateur d√©tect√© automatiquement : `{detected_sep}`")
        except Exception:
            # Si √©chec ‚Üí s√©lection manuelle
            detected_sep = st.selectbox(
                "S√©parateur √† utiliser :",
                [",", ";", "\t", "|", " "],
                format_func=lambda x: "Tabulation" if x == "\t" else f"'{x}'"
            )

        # Chargement r√©el du DataFrame
        try:
            df = pd.read_csv(StringIO(raw_text), sep=detected_sep)
        except Exception as e:
            st.error(f"‚ùå Erreur de lecture du fichier : {e}")

    # ‚¨áÔ∏è Chargement JSON
    elif file_extension == "json":
        try:
            uploaded_file.seek(0)
            df = pd.read_json(uploaded_file)
        except Exception as e:
            st.error(f"‚ùå Erreur de lecture JSON : {e}")

    # ‚¨áÔ∏è Chargement Excel
    elif file_extension == "xlsx":
        try:
            df = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"‚ùå Erreur de lecture Excel : {e}")

    # ‚¨áÔ∏è Chargement Parquet
    elif file_extension == "parquet":
        try:
            df = pd.read_parquet(uploaded_file)
        except Exception as e:
            st.error(f"‚ùå Erreur de lecture Parquet : {e}")

# =============================================================================
# ‚úÖ Aper√ßu du DataFrame + colonnes
# =============================================================================
if df is not None:
    try:
        st.success("‚úÖ Fichier charg√© avec succ√®s.")

        # Slider pour afficher un nombre de lignes personnalisable
        max_rows = st.radio(
            "Nombre de lignes √† afficher :",
            [5, 10, 20, 50, 100],
            horizontal=True
        )

        # M√©triques sur les dimensions
        col1, col2 = st.columns(2)
        col1.metric("Nombre de lignes", f"{df.shape[0]:,}".replace(",", "‚ÄØ"))
        col2.metric("Nombre de colonnes", f"{df.shape[1]:,}".replace(",", "‚ÄØ"))


        # Affichage des premi√®res lignes
        st.dataframe(df.head(max_rows), use_container_width=True)

 
    except Exception as e:
        st.error(f"‚ùå Probl√®me lors de l‚Äôaffichage du DataFrame : {e}")

# =============================================================================
# 2. üîç ANALYSE EXPLORATOIRE G√âN√âRALE
# =============================================================================

# Si un fichier a √©t√© charg√© avec succ√®s, continuer l'analyse
if df is not None:
    st.markdown("### üîç 2. Analyse exploratoire g√©n√©rale")
    st.markdown("---")

    # üîé Bloc 2.1 ‚Äì D√©tail des types de variables + infos
    with st.expander("üìå D√©tail des types de variables d√©tect√©s"):

        st.info("üéØ Aper√ßu des colonnes avec type d√©tect√©, nombre de valeurs uniques et % de valeurs manquantes.")

        # Cr√©ation d'un DataFrame descriptif des variables
        type_summary = pd.DataFrame({
            "Nom de la colonne": df.columns,
            "Type pandas": df.dtypes.astype(str),
            "Nb valeurs uniques": df.nunique(),
            "% de valeurs manquantes": (df.isna().mean() * 100).round(1).astype(str) + "‚ÄØ%",
            "Exemple de valeur": [df[col].dropna().astype(str).unique()[0] if df[col].dropna().shape[0] > 0 else "‚Äî" for col in df.columns]
        })

        # Tri par types
        type_summary = type_summary.sort_values("Type pandas")

        # Affichage
        st.dataframe(type_summary, use_container_width=True, height=500)

    # S√©paration des colonnes num√©riques et cat√©gorielles pour faciliter l'analyse
    num_cols = df.select_dtypes(include=["number"]).columns.tolist()  # Colonnes num√©riques
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()  # Colonnes cat√©gorielles

    # Si aucune colonne num√©rique n'est d√©tect√©e, afficher une alerte et stopper l'ex√©cution de l'analyse
    if not num_cols:
        st.warning("‚ö†Ô∏è Aucune variable num√©rique d√©tect√©e.")
        st.stop()

    # SECTION : Histogrammes des distributions pour les variables num√©riques
    with st.expander("üìà Distributions des variables num√©riques"):
        # Permet √† l'utilisateur de s√©lectionner une variable num√©rique via un menu d√©roulant
        col = st.selectbox("S√©lectionner une variable", num_cols)
        # G√©n√®re et affiche un histogramme interactif avec Plotly Express pour la variable choisie
        st.plotly_chart(px.histogram(df, x=col), use_container_width=True)

    # SECTION : Analyse des valeurs aberrantes (outliers) √† l'aide de la m√©thode IQR
    with st.expander("üö® Analyse des outliers (IQR)"):
        # Menu d√©roulant pour choisir la variable num√©rique √† analyser pour les outliers
        col = st.selectbox("Variable num√©rique √† analyser", num_cols, key="iqr_col")
        # Utilise la fonction 'detect_outliers_iqr' pour d√©tecter les outliers dans la variable s√©lectionn√©e
        outliers = detect_outliers_iqr(df, col)
        # Affiche le nombre d'outliers d√©tect√©s
        st.write(f"{len(outliers)} outliers d√©tect√©s.")
        # Affiche un aper√ßu des outliers dans un tableau interactif
        st.dataframe(outliers)

    # SECTION : Analyse graphique des valeurs manquantes
    with st.expander("üìâ Analyse personnalis√©e des valeurs manquantes", expanded=True):
        # Cr√©ation d'un slider pour d√©finir le seuil de valeurs manquantes (en pourcentage)
        seuil_pct = st.slider("üõ†Ô∏è D√©finir le seuil (%)", 0, 100, 20)
        seuil = seuil_pct / 100  # Conversion en fraction (0 √† 1)
        # Slider pour d√©finir le nombre de colonnes √† afficher dans le graphique
        top_n = st.slider("üìå Nombre de colonnes √† afficher", 5, 50, 15)

        # G√©n√©ration du graphique des valeurs manquantes gr√¢ce √† la fonction 'plot_missing_values'
        fig = plot_missing_values(df, seuil=seuil, top_n=top_n)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("‚úÖ Aucune valeur manquante √† visualiser.")

        # Identification des colonnes dont le taux de valeurs manquantes d√©passe le seuil d√©fini
        cols_to_remove = get_columns_above_threshold(df, seuil=seuil)
        if cols_to_remove:
            st.warning(f"üö® {len(cols_to_remove)} colonnes d√©passent le seuil de {seuil_pct}%")
            # Affiche la liste des colonnes √† supprimer
            st.code(", ".join(cols_to_remove), language="text")

        # Option pour supprimer manuellement les colonnes d√©passant le seuil de valeurs manquantes
        if cols_to_remove and st.checkbox("Supprimer ces colonnes"):
            # Suppression des colonnes et r√©cup√©ration de la liste des colonnes supprim√©es
            df, dropped = drop_missing_columns(df, seuil=seuil)
            # Enregistrement de la transformation dans le log
            log_transformation(f"{len(dropped)} colonnes supprim√©es pour d√©passement du seuil {seuil_pct}%.")
            st.success(f"{len(dropped)} colonnes supprim√©es.")

    # SECTION : Suggestions automatiques de nettoyage (colonnes constantes, faible variance, valeurs manquantes)
    with st.expander("üßπ Suggestions de nettoyage"):
        st.info("Colonnes potentiellement inutiles √† retirer automatiquement.")
        # Affiche les colonnes constantes d√©tect√©es
        st.write("üî∏ Colonnes constantes :", detect_constant_columns(df))
        # Affiche les colonnes √† faible variance d√©tect√©es
        st.write("üî∏ Faible variance :", detect_low_variance_columns(df))
        # Calcul et affichage du taux de valeurs manquantes pour chaque colonne, en filtrant celles pr√©sentant des valeurs manquantes
        missing = df.isnull().mean().sort_values(ascending=False)
        st.write("üî∏ Valeurs manquantes :", missing[missing > 0])

    # SECTION : Nettoyage manuel des donn√©es (suppression de doublons et de colonnes s√©lectionn√©es)
    with st.expander("üßº Nettoyage manuel"):
        # Bouton pour supprimer les doublons du DataFrame
        if st.button("üîÅ Supprimer les doublons"):
            initial_len = len(df)  # Nombre initial de lignes
            df = df.drop_duplicates()  # Suppression des doublons
            removed = initial_len - len(df)  # Calcul du nombre de doublons supprim√©s
            log_transformation(f"{removed} doublons supprim√©s localement.")
            st.success(f"{removed} doublons supprim√©s.")

        # Permet √† l'utilisateur de s√©lectionner manuellement les colonnes √† supprimer via une liste multis√©lection
        cols_to_drop = st.multiselect("S√©lectionner les colonnes √† supprimer", df.columns.tolist())
        if cols_to_drop and st.button("üóëÔ∏è Supprimer les colonnes s√©lectionn√©es"):
            df.drop(columns=cols_to_drop, inplace=True)  # Suppression des colonnes s√©lectionn√©es
            log_transformation(f"Colonnes supprim√©es manuellement : {', '.join(cols_to_drop)}")
            st.success("Colonnes supprim√©es.")


# =============================================================================
# 3. üéØ ANALYSE ORIENT√âE VARIABLE CIBLE
# =============================================================================

if df is not None:
    st.markdown("### üéØ 3. Analyse orient√©e variable cible")
    st.markdown("---")

    # SECTION : S√©lection des variables cibles principales et secondaires
    # Permet √† l'utilisateur de choisir une variable cible principale parmi les variables num√©riques
    target_1 = st.selectbox("üéØ Variable cible principale", num_cols, key="target1")
    # Optionnel : choix d'une seconde variable cible
    target_2 = st.selectbox("üéØ Variable cible secondaire (optionnel)", [None] + num_cols, key="target2")

    # SECTION : Analyse des corr√©lations lin√©aires avec la variable cible principale
    with st.expander("üìä Corr√©lations avec la cible"):
        st.info("Corr√©lations lin√©aires (Pearson).")
        # Calcul de la corr√©lation de Pearson entre la variable cible et toutes les autres variables num√©riques
        corr = df.select_dtypes(include=["number"]).corr()[target_1].drop(target_1).sort_values(ascending=False)
        st.dataframe(corr)
        # Affichage d'un graphique en barres des corr√©lations pour une meilleure visualisation
        st.plotly_chart(px.bar(corr.reset_index(), x="index", y=target_1), use_container_width=True)

    # SECTION : Analyse de la moyenne de la variable cible par groupe (pour une variable cat√©gorielle)
    with st.expander("üìà Graphiques exploratoires m√©tiers"):
        # S√©lection d'une variable cat√©gorielle pour regrouper les donn√©es
        group_col = st.selectbox("Variable cat√©gorielle", cat_cols, key="groupcol")
        # Calcul de la moyenne de la variable cible principale pour chaque groupe
        avg_target1 = df.groupby(group_col)[target_1].mean().sort_values(ascending=False).reset_index()
        # Affichage du graphique en barres correspondant
        st.plotly_chart(px.bar(avg_target1, x=group_col, y=target_1), use_container_width=True)

        # Si une variable cible secondaire est s√©lectionn√©e, r√©aliser la m√™me analyse
        if target_2:
            avg_target2 = df.groupby(group_col)[target_2].mean().sort_values(ascending=False).reset_index()
            st.plotly_chart(px.bar(avg_target2, x=group_col, y=target_2), use_container_width=True)

    # SECTION : Encodage des variables cat√©gorielles
    with st.expander("üîÑ Encodage des variables cat√©gorielles"):
        # S√©lection multiple des colonnes cat√©gorielles √† encoder
        selected = st.multiselect("Colonnes √† encoder", cat_cols)
        # Choix de la m√©thode d'encodage (onehot ou ordinal)
        method = st.radio("M√©thode", ["onehot", "ordinal"])
        if st.button("Encoder"):
            # Appliquer l'encodage sur une copie du DataFrame pour ne pas alt√©rer l'original
            df_encoded = encode_categorical(df.copy(), method=method, columns=selected)
            st.success(f"{len(selected)} colonnes encod√©es avec la m√©thode '{method}'.")
            # Afficher les premi√®res lignes du DataFrame encod√© pour v√©rification
            st.dataframe(df_encoded.head())

    # SECTION : Boxplot interactif pour visualiser la distribution d'une variable num√©rique selon une cat√©gorisation
    with st.expander("üì¶ Boxplot interactif"):
        # Choix de la variable cat√©gorielle pour l'axe des X
        cat_col = st.selectbox("X = variable cat√©gorielle", cat_cols, key="box_cat")
        # Choix de la variable num√©rique pour l'axe des Y
        num_col = st.selectbox("Y = variable num√©rique", num_cols, key="box_num")
        # Cr√©ation du boxplot interactif avec Plotly Express
        st.plotly_chart(px.box(df, x=cat_col, y=num_col), use_container_width=True)

    # SECTION : Nuage de points (scatter plot) pour analyser la relation entre deux variables num√©riques
    with st.expander("üßÆ Scatter Plot interactif"):
        # S√©lection de la variable pour l'axe X
        x = st.selectbox("X", num_cols, key="xscatter")
        # S√©lection de la variable pour l'axe Y
        y = st.selectbox("Y", num_cols, key="yscatter")
        # Optionnel : choix d'une variable cat√©gorielle pour colorer les points
        color = st.selectbox("Couleur (optionnelle)", [None] + cat_cols, key="color_scatter")
        st.plotly_chart(px.scatter(df, x=x, y=y, color=color), use_container_width=True)

    # SECTION : Graphique crois√© affichant la moyenne de la variable cible par combinaison de deux variables cat√©gorielles
    with st.expander("üîÄ Graphique crois√© (moyenne cible)"):
        # S√©lection de la premi√®re variable cat√©gorielle
        cat1 = st.selectbox("Cat√©gorie X", cat_cols, key="group1")
        # S√©lection de la seconde variable cat√©gorielle pour la couleur
        cat2 = st.selectbox("Cat√©gorie couleur", cat_cols, key="group2")
        # Calcul de la moyenne de la variable cible principale par combinaison des deux cat√©gories
        agg_df = (
            df.groupby([cat1, cat2])[target_1]
            .mean()
            .rename("mean_value")
            .reset_index()
        )
        # Cr√©ation d'un graphique en barres group√©es pour visualiser ces moyennes
        fig2d = px.bar(
            agg_df,
            x=cat1,
            y="mean_value",
            color=cat2,
            barmode="group",
            title=f"{target_1} moyen par {cat1} et {cat2}"
        )
        st.plotly_chart(fig2d, use_container_width=True)


# =============================================================================
# 4. üíæ EXPORT DU FICHIER NETTOY√â
# =============================================================================

if df is not None:
    st.markdown("### üíæ 4. Export du fichier final")
    st.markdown("---")

    # SECTION : Exportation du DataFrame nettoy√© sous forme de fichier CSV
    with st.expander("üíæ Export CSV", expanded=True):
        # Cr√©ation d'un formulaire Streamlit pour g√©rer le t√©l√©chargement du fichier
        with st.form("export_form"):
            # Champ de texte pour permettre √† l'utilisateur de d√©finir le nom du fichier CSV
            file_name = st.text_input("Nom du fichier CSV", value="cleaned_data.csv")
            # Bouton de soumission du formulaire
            submit = st.form_submit_button("üì• T√©l√©charger")
            if submit:
                # Conversion du DataFrame en fichier CSV encod√© en UTF-8 (sans index)
                csv = df.to_csv(index=False).encode('utf-8')
                # Cr√©ation d'un bouton de t√©l√©chargement permettant √† l'utilisateur de r√©cup√©rer le fichier CSV
                st.download_button("T√©l√©charger", csv, file_name=file_name, mime="text/csv")



