# utils/eda_utils.py

# =============================================================================
# üìö IMPORTATION DES LIBRAIRIES
# =============================================================================

# Importation de pandas pour la manipulation de donn√©es sous forme de DataFrame
import pandas as pd  
# Importation de numpy pour les op√©rations num√©riques et math√©matiques
import numpy as np  
# Importation des classes OneHotEncoder et OrdinalEncoder de sklearn pour encoder des variables cat√©gorielles
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder  
# Importation de Plotly Express pour cr√©er des graphiques interactifs
import plotly.express as px  


# =============================================================================
# üîé D√âTECTION DES TYPES DE VARIABLES
# =============================================================================
def detect_variable_types(df: pd.DataFrame) -> pd.DataFrame:
    """
    D√©tecte automatiquement le type de chaque colonne d'un DataFrame et renvoie un r√©sum√©.
    
    Les types sont d√©termin√©s de la fa√ßon suivante :
      - Colonnes num√©riques : "num√©rique" ou "binaire" (si exactement 2 valeurs uniques)
      - Colonnes non num√©riques avec moins de 20 valeurs uniques : "cat√©gorielle"
      - Autres colonnes : "texte libre"
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† analyser.
    
    Retourne:
      - pd.DataFrame
          Un DataFrame r√©sumant le nom de la colonne, le type d√©tect√©, le dtype et le nombre de valeurs uniques.
    """
    types = []  # Liste pour stocker les informations de chaque colonne
    for col in df.columns:
        unique_vals = df[col].nunique()  # Nombre de valeurs uniques dans la colonne
        dtype = df[col].dtype  # Type de donn√©es de la colonne

        # V√©rifie si la colonne est num√©rique
        if pd.api.types.is_numeric_dtype(df[col]):
            # Si la colonne poss√®de exactement 2 valeurs uniques, on la consid√®re comme binaire
            var_type = "binaire" if unique_vals == 2 else "num√©rique"
        # Si la colonne n'est pas num√©rique et a moins de 20 valeurs uniques, on la consid√®re comme cat√©gorielle
        elif unique_vals < 20:
            var_type = "cat√©gorielle"
        # Sinon, on la consid√®re comme contenant du texte libre
        else:
            var_type = "texte libre"

        # Ajoute les informations de la colonne sous forme de dictionnaire dans la liste
        types.append({
            "colonne": col,
            "type": var_type,
            "dtype": str(dtype),
            "valeurs_uniques": unique_vals
        })

    # Convertit la liste de dictionnaires en DataFrame pour un affichage structur√©
    return pd.DataFrame(types)


# =============================================================================
# üîÅ MATRICE DE CORR√âLATION (PERSONNALISABLE)
# =============================================================================
def compute_correlation_matrix(df: pd.DataFrame, method: str = 'pearson') -> pd.DataFrame:
    """
    Calcule la matrice de corr√©lation pour les colonnes num√©riques du DataFrame en utilisant
    la m√©thode sp√©cifi√©e (par d√©faut 'pearson').
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame contenant les donn√©es.
      - method: str, optionnel (par d√©faut 'pearson')
          La m√©thode de corr√©lation ('pearson', 'kendall' ou 'spearman').
    
    Retourne:
      - pd.DataFrame
          La matrice de corr√©lation calcul√©e sur les colonnes num√©riques.
    """
    # S√©lectionne uniquement les colonnes num√©riques
    numeric_df = df.select_dtypes(include=[np.number])
    # Calcule et retourne la matrice de corr√©lation avec la m√©thode choisie
    return numeric_df.corr(method=method)


# =============================================================================
# üö® D√âTECTION DES OUTLIERS PAR IQR + MARQUEUR
# =============================================================================
def detect_outliers_iqr(df: pd.DataFrame, column: str) -> pd.DataFrame:
    """
    D√©tecte les valeurs aberrantes (outliers) dans une colonne num√©rique d'un DataFrame
    en utilisant la m√©thode de l'Intervalle Interquartile (IQR).
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame contenant les donn√©es.
      - column: str
          Le nom de la colonne sur laquelle appliquer la d√©tection des outliers.
    
    Retourne:
      - pd.DataFrame
          Un DataFrame contenant uniquement les lignes o√π la valeur est consid√©r√©e comme un outlier.
          Une colonne 'is_outlier' est ajout√©e pour marquer ces valeurs.
    """
    # Calcul du 1er quartile (25e percentile)
    Q1 = df[column].quantile(0.25)
    # Calcul du 3e quartile (75e percentile)
    Q3 = df[column].quantile(0.75)
    # Calcul de l'intervalle interquartile
    IQR = Q3 - Q1
    # D√©finition des bornes inf√©rieure et sup√©rieure pour d√©tecter les outliers
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    # Cr√©e une copie du DataFrame pour √©viter de modifier l'original
    result = df.copy()
    # Ajoute une colonne bool√©enne indiquant si la valeur est un outlier
    result["is_outlier"] = (df[column] < lower) | (df[column] > upper)
    # Retourne uniquement les lignes o√π 'is_outlier' est True
    return result[result["is_outlier"]]


# =============================================================================
# üìå D√âTECTION DES COLONNES CONSTANTES
# =============================================================================
def detect_constant_columns(df: pd.DataFrame) -> list:
    """
    Identifie les colonnes du DataFrame qui contiennent une seule valeur unique 
    (y compris les valeurs manquantes).
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† analyser.
    
    Retourne:
      - list
          Une liste contenant les noms des colonnes constantes.
    """
    # Retourne les colonnes o√π le nombre de valeurs uniques (NaN inclus) est √©gal √† 1
    return [col for col in df.columns if df[col].nunique(dropna=False) == 1]


# =============================================================================
# üßÆ D√âTECTION DES COLONNES √Ä FAIBLE VARIANCE
# =============================================================================
def detect_low_variance_columns(df: pd.DataFrame, threshold: float = 0.01) -> list:
    """
    Identifie les colonnes num√©riques ayant une variance inf√©rieure au seuil sp√©cifi√©.
    
    Une faible variance peut indiquer que la colonne apporte peu d'information.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame contenant les donn√©es.
      - threshold: float, optionnel (par d√©faut 0.01)
          Le seuil de variance sous lequel une colonne est consid√©r√©e comme √† faible variance.
    
    Retourne:
      - list
          Une liste contenant les noms des colonnes dont la variance est inf√©rieure au seuil.
    """
    # S√©lectionne les colonnes num√©riques
    num_df = df.select_dtypes(include=[np.number])
    # Calcule la variance de chaque colonne num√©rique
    variances = num_df.var()
    # Retourne la liste des colonnes dont la variance est inf√©rieure au seuil
    return variances[variances < threshold].index.tolist()


# =============================================================================
# üîÑ ENCODAGE DES VARIABLES CAT√âGORIELLES
# =============================================================================
def encode_categorical(df: pd.DataFrame, method: str = "onehot", columns: list | None = None) -> pd.DataFrame:
    """
    Encode les variables cat√©gorielles d'un DataFrame en utilisant soit un encodage OneHot
    (cr√©ation de colonnes binaires pour chaque cat√©gorie) soit un encodage ordinal (transformation
    en entiers ordonn√©s).
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame contenant les donn√©es √† encoder.
      - method: str, optionnel (par d√©faut "onehot")
          La m√©thode d'encodage √† utiliser. Options : "onehot" ou "ordinal".
      - columns: list ou None, optionnel
          La liste des colonnes √† encoder. Si None, toutes les colonnes de type object ou category sont encod√©es.
    
    Retourne:
      - pd.DataFrame
          Un nouveau DataFrame avec les variables cat√©gorielles encod√©es.
    
    L√®ve:
      - ValueError si aucune colonne cat√©gorielle n'est trouv√©e ou si la m√©thode sp√©cifi√©e est inconnue.
    """
    # Cr√©e une copie du DataFrame pour √©viter d'alt√©rer l'original
    df = df.copy()
    
    # Si aucune liste de colonnes n'est fournie, s√©lectionne automatiquement toutes les colonnes de type object ou category
    if columns is None:
        columns = df.select_dtypes(include=["object", "category"]).columns.tolist()

    # Si aucune colonne n'est identifi√©e, l√®ve une exception
    if not columns:
        raise ValueError("Aucune colonne cat√©gorielle √† encoder.")

    # Encodage OneHot : conversion en variables binaires pour chaque cat√©gorie
    if method == "onehot":
        return pd.get_dummies(df, columns=columns)
    # Encodage ordinal : conversion en entiers ordonn√©s
    elif method == "ordinal":
        # Remplit les valeurs manquantes par la cha√Æne "manquant" pour √©viter les erreurs
        df[columns] = df[columns].fillna("manquant")
        # Instanciation de l'encodeur ordinal avec gestion des inconnues (valeur -1)
        encoder = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
        # Application de l'encodage sur les colonnes s√©lectionn√©es
        df[columns] = encoder.fit_transform(df[columns])
        return df
    else:
        # L√®ve une exception si la m√©thode sp√©cifi√©e n'est pas reconnue
        raise ValueError("M√©thode d'encodage inconnue : choisir 'onehot' ou 'ordinal'")


# =============================================================================
# üìâ ANALYSE DES VALEURS MANQUANTES
# =============================================================================
def plot_missing_values(df: pd.DataFrame, seuil: float = 0.3, top_n: int = 20):
    """
    G√©n√®re un graphique interactif sous forme de barre pour visualiser le pourcentage
    de valeurs manquantes par colonne dans le DataFrame.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† analyser.
      - seuil: float, optionnel (par d√©faut 0.3)
          Le seuil relatif (sous forme de fraction) pour d√©terminer la couleur du graphique.
          Les colonnes avec un pourcentage de valeurs manquantes sup√©rieur √† (seuil*100)
          seront color√©es en rouge, sinon en bleu.
      - top_n: int, optionnel (par d√©faut 20)
          Le nombre maximum de colonnes √† afficher dans le graphique.
    
    Retourne:
      - plotly.graph_objects.Figure ou None
          Le graphique interactif g√©n√©r√©, ou None si aucune valeur manquante n'est pr√©sente.
    """
    # Calcul du nombre total de valeurs manquantes par colonne
    missing_values = df.isnull().sum()
    # Calcul du pourcentage de valeurs manquantes par colonne
    missing_percent = (missing_values / len(df)) * 100

    # Cr√©ation d'un DataFrame r√©capitulatif avec le nom de la colonne, le total et le pourcentage de valeurs manquantes
    missing_summary = pd.DataFrame({
        'Colonnes': df.columns,
        'Total Manquantes': missing_values,
        'Pourcentage Manquantes (%)': missing_percent
    })

    # D√©termine la couleur pour chaque colonne en fonction du seuil :
    # 'red' si le pourcentage d√©passe (seuil*100), sinon 'blue'
    missing_summary['Color'] = missing_summary['Pourcentage Manquantes (%)'].apply(
        lambda pct: 'red' if pct > (seuil * 100) else 'blue'
    )

    # Filtre les colonnes ayant au moins une valeur manquante
    missing_data_filtered = missing_summary[missing_summary['Total Manquantes'] > 0]
    # Trie les colonnes par pourcentage d√©croissant et s√©lectionne les top_n colonnes
    missing_data_filtered = missing_data_filtered.sort_values(by='Pourcentage Manquantes (%)', ascending=False).head(top_n)

    # Si aucune colonne avec des valeurs manquantes n'est trouv√©e, retourne None
    if missing_data_filtered.empty:
        return None

    # Cr√©e un graphique √† barres interactif avec Plotly Express
    fig = px.bar(
        missing_data_filtered,
        x='Colonnes',
        y='Pourcentage Manquantes (%)',
        color='Color',
        title="Pourcentage de valeurs manquantes",
        text='Pourcentage Manquantes (%)',
        color_discrete_map={'red': 'red', 'blue': 'blue'}
    )
    # Formate le texte affich√© sur les barres avec deux d√©cimales
    fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
    # Met √† jour la mise en page du graphique (fond blanc, angle des ticks de l'axe X, etc.)
    fig.update_layout(
        plot_bgcolor='white',
        xaxis=dict(title="Colonnes", tickangle=45),
        yaxis=dict(title="% de valeurs manquantes"),
        showlegend=False,
        height=600
    )

    # Retourne le graphique g√©n√©r√©
    return fig


def get_columns_above_threshold(df: pd.DataFrame, seuil: float) -> list:
    """
    Identifie les colonnes dont le pourcentage de valeurs manquantes est sup√©rieur
    ou √©gal au seuil sp√©cifi√©.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† analyser.
      - seuil: float
          Le seuil (entre 0 et 1) pour d√©terminer si une colonne a trop de valeurs manquantes.
    
    Retourne:
      - list
          Une liste des colonnes d√©passant le seuil de valeurs manquantes.
    """
    # Calcule la proportion de valeurs manquantes pour chaque colonne et retourne celles qui d√©passent le seuil
    return df.columns[df.isna().mean() >= seuil].tolist()


def drop_missing_columns(df: pd.DataFrame, seuil: float):
    """
    Supprime les colonnes d'un DataFrame dont le pourcentage de valeurs manquantes
    est sup√©rieur ou √©gal au seuil donn√©.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† nettoyer.
      - seuil: float
          Le seuil (entre 0 et 1) pour d√©terminer quelles colonnes supprimer.
    
    Retourne:
      - tuple:
          * Le DataFrame apr√®s suppression des colonnes.
          * La liste des colonnes supprim√©es.
    """
    # R√©cup√®re la liste des colonnes √† supprimer en fonction du seuil
    cols_to_drop = get_columns_above_threshold(df, seuil)
    # Retourne le DataFrame modifi√© et la liste des colonnes supprim√©es
    return df.drop(columns=cols_to_drop), cols_to_drop


# =============================================================================
# ‚ûï FONCTIONS SUPPL√âMENTAIRES POUR ANALYSE AVANC√âE
# =============================================================================
def get_top_correlations(df: pd.DataFrame, target: str, top_n: int = 10) -> pd.Series:
    """
    Calcule et retourne les corr√©lations absolues les plus √©lev√©es d'une variable cible 
    par rapport aux autres variables num√©riques.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame contenant les donn√©es.
      - target: str
          Le nom de la variable cible pour laquelle calculer les corr√©lations.
      - top_n: int, optionnel (par d√©faut 10)
          Le nombre de variables les plus corr√©l√©es √† retourner.
    
    Retourne:
      - pd.Series
          Une s√©rie contenant les corr√©lations absolues les plus √©lev√©es pour la variable cible.
    """
    return df.corr()[target].drop(target).abs().sort_values(ascending=False).head(top_n)


def detect_skewed_distributions(df: pd.DataFrame, threshold: float = 1.0) -> dict:
    """
    Identifie les distributions asym√©triques parmi les colonnes num√©riques du DataFrame.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† analyser.
      - threshold: float, optionnel (par d√©faut 1.0)
          Le seuil √† partir duquel une distribution est consid√©r√©e comme asym√©trique.
    
    Retourne:
      - dict
          Un dictionnaire o√π chaque cl√© est le nom d'une colonne et la valeur correspondante est 
          le coefficient d'asym√©trie, pour les colonnes dont l'asym√©trie absolue d√©passe le seuil.
    """
    # S√©lectionne les colonnes num√©riques
    num_df = df.select_dtypes(include=[np.number])
    # Calcule l'asym√©trie pour chaque colonne et trie par ordre d√©croissant
    skewness = num_df.skew().sort_values(ascending=False)
    # Retourne sous forme de dictionnaire les colonnes dont l'asym√©trie d√©passe le seuil en valeur absolue
    return skewness[abs(skewness) > threshold].to_dict()


def summarize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    G√©n√®re un r√©sum√© statistique complet du DataFrame, incluant les statistiques descriptives,
    le pourcentage de valeurs manquantes et le type de donn√©es de chaque colonne.
    
    Param√®tres:
      - df: pd.DataFrame
          Le DataFrame √† r√©sumer.
    
    Retourne:
      - pd.DataFrame
          Un DataFrame contenant le r√©sum√© statistique et des informations compl√©mentaires pour chaque colonne.
    """
    # Calcule les statistiques descriptives pour toutes les colonnes et transpose le r√©sultat pour la lisibilit√©
    summary = df.describe(include='all').transpose()
    # Ajoute une colonne indiquant le pourcentage de valeurs manquantes pour chaque colonne
    summary['missing (%)'] = df.isnull().mean() * 100
    # Ajoute une colonne avec le type de donn√©es de chaque colonne
    summary['dtype'] = df.dtypes
    return summary
