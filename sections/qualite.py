# ============================================================
# Fichier : sections/qualite.py
# Objectif : √âvaluation de la qualit√© des donn√©es (score + anomalies)
# Version  : unifi√©e (UI harmonis√©e, √©tape EDA = "stats")
# Auteur   : Xavier Rousseau
# ============================================================

from __future__ import annotations

import pandas as pd
import plotly.express as px
import streamlit as st

from utils.steps import EDA_STEPS
from utils.eda_utils import (
    detect_constant_columns,
    get_columns_above_threshold,
    detect_outliers,
)

from utils.snapshot_utils import save_snapshot
from utils.log_utils import log_action
from utils.filters import get_active_dataframe, validate_step_button
from utils.ui_utils import section_header, show_footer


# =============================== Helpers internes ==============================

def _compute_quality_score(df: pd.DataFrame) -> int:
    """
    Calcule un score de qualit√© tr√®s lisible sur 100.
    Heuristique volontairement simple, facile √† expliquer :

      - P√©nalit√© NA : moyenne des NA (% cellules vides) √ó 40 points.
      - P√©nalit√© doublons : 20 points si au moins une ligne dupliqu√©e.
      - P√©nalit√© colonnes constantes : part des colonnes √† 1 modalit√© √ó 40 points.

    Le score est born√© √† [0, 100].

    Remarque : c‚Äôest un barom√®tre p√©dagogique, pas un indicateur normatif.
    """
    if df.empty:
        return 0
    na_penalty    = df.isna().mean().mean() * 40
    dup_penalty   = 20 if df.duplicated().any() else 0
    const_penalty = (df.nunique() <= 1).sum() / max(1, df.shape[1]) * 40
    return max(0, int(100 - (na_penalty + dup_penalty + const_penalty)))


def _find_placeholder_values(df: pd.DataFrame) -> pd.DataFrame:
    """
    D√©tecte quelques valeurs ¬´ placeholders ¬ª courantes (insensibles √† la casse).

    Valeurs : {"unknown","n/a","na","undefined","none","missing","?"}

    Retourne un DataFrame (colonne -> nb d‚Äôoccurrences) filtr√© sur > 0.
    """
    placeholder_values = {"unknown", "n/a", "na", "undefined", "none", "missing", "?"}
    hits = {
        col: int(df[col].astype(str).str.lower().isin(placeholder_values).sum())
        for col in df.columns
    }
    hits = {k: v for k, v in hits.items() if v > 0}
    return pd.DataFrame.from_dict(hits, orient="index", columns=["Occurrences"]) if hits else pd.DataFrame()


# ================================== Vue =======================================

def run_qualite() -> None:
    """
    Tableau ¬´ Qualit√© ¬ª :
      - Score global compr√©hensible (0‚Äì100) bas√© sur NA, doublons, colonnes constantes.
      - R√©sum√© des anomalies typiques (NA>50%, constantes, doublons).
      - V√©rifications cibl√©es : num√©riques encod√©s en texte, noms suspects, placeholders.
      - Coup d‚Äô≈ìil outliers (z-score>3) pour chaque variable num√©rique.
      - Liste de colonnes candidates √† suppression + correction semi-auto.

    Effets :
      - Certaines actions modifient `st.session_state["df"]` in-place,
        cr√©ent un snapshot et loguent l‚Äôaction.
    """
    # ---------- En-t√™te + barre compacte ----------
    section_header(
        title="Qualit√©",
        subtitle="√âvaluez la qualit√© des donn√©es (score global, doublons, placeholders, outliers‚Ä¶).",
        section="qualite",  # ‚Üê utilise SECTION_BANNERS["qualite"]
        emoji="",
    )

    # ---------- DataFrame actif ----------
    df, nom = get_active_dataframe()
    if df is None or df.empty:
        st.warning("‚ùå Aucun fichier actif ou fichier vide. S√©lectionnez un fichier dans l‚Äôonglet **Chargement**.")
        return

    # ---------- Score global (p√©dagogique) ----------
    st.markdown("### üå∏ Score global de qualit√©")
    score = _compute_quality_score(df)
    st.subheader(f"üåü **{score} / 100**")
    st.caption(
        "Le score combine le taux de valeurs manquantes, la pr√©sence de doublons et la part de colonnes constantes. "
        "C‚Äôest un indicateur p√©dagogique pour prioriser les actions."
    )
    st.divider()

    # ---------- R√©sum√© des anomalies ----------
    st.markdown("### üßæ R√©sum√© des anomalies")
    nb_const = int((df.nunique() <= 1).sum())
    nb_na50  = int((df.isna().mean() > 0.5).sum())
    nb_dup   = int(df.duplicated().sum())

    st.markdown(
        f"- üîÅ **{nb_dup} lignes dupliqu√©es**  \n"
        f"- üü® **{nb_na50} colonnes avec >50% de NA**  \n"
        f"- üßä **{nb_const} colonnes constantes**"
    )
    st.divider()

    # ---------- Heatmap NA (optionnelle) ----------
    # Note perf : px.imshow sur de tr√®s gros tableaux peut √™tre co√ªteux.
    # On laisse l‚Äôutilisateur d√©cider via une case √† cocher.
    if st.checkbox("üìä Afficher la heatmap des NA"):
        if df.size > 1_000_000:
            st.warning("‚ö†Ô∏è Tableau volumineux : l‚Äôaffichage peut √™tre lent.")
        fig = px.imshow(
            df.isna(),
            aspect="auto",
            color_continuous_scale="Blues",
            title="Carte des valeurs manquantes",
        )
        st.plotly_chart(fig, use_container_width=True)
    st.divider()

    # ---------- V√©rifications suppl√©mentaires ----------
    st.markdown("### ü©∫ V√©rifications suppl√©mentaires")

    # (1) Colonnes 'object' susceptibles d‚Äô√™tre des num√©riques encod√©s en texte.
    # Heuristique : apr√®s suppression des '.' et ',' (formats d√©cimaux), >=80% de str.isnumeric().
    suspect_numeric_as_str = [
        col for col in df.select_dtypes(include="object").columns
        if df[col].astype(str)
              .str.replace(".", "", regex=False)
              .str.replace(",", "", regex=False)
              .str.isnumeric().mean() > 0.8
    ]
    if suspect_numeric_as_str:
        st.warning("üî¢ Colonnes `object` contenant majoritairement des chiffres (potentiel typage √† corriger) :")
        st.code(", ".join(suspect_numeric_as_str))

    # (2) Noms de colonnes suspects : 'Unnamed' (Excel), ou pr√©sence de 'id'
    suspect_names = [col for col in df.columns if col.startswith("Unnamed") or "id" in col.lower()]
    if suspect_names:
        st.warning("üìõ Noms de colonnes suspects :")
        st.code(", ".join(suspect_names))

    # (3) Valeurs placeholders
    placeholder_df = _find_placeholder_values(df)
    if not placeholder_df.empty:
        st.warning("‚ùì Valeurs placeholders d√©tect√©es :")
        st.dataframe(placeholder_df, use_container_width=True)
    st.divider()

    # ---------- Outliers globaux (z-score > 3) ----------
    st.markdown("### üìâ Valeurs extr√™mes (Z-score > 3)")
    num_cols = df.select_dtypes(include="number").columns.tolist()
    out_counts: dict[str, int] = {}
    for col in num_cols:
        s = df[col].dropna()
        if s.empty or s.std(ddof=0) == 0:
            continue
        try:
            out_idx_or_df = detect_outliers(df[[col]], method="zscore", threshold=3.0)
            out_counts[col] = int(out_idx_or_df.shape[0]) if isinstance(out_idx_or_df, pd.DataFrame) else int(len(out_idx_or_df))
        except Exception:
            # On ignore silencieusement une colonne probl√©matique (types inattendus, etc.).
            continue

    if out_counts:
        st.warning("üö® Outliers d√©tect√©s :")
        st.dataframe(pd.DataFrame.from_dict(out_counts, orient="index", columns=["Nb outliers"]))
        st.caption("Astuce : utilisez l‚Äôonglet **Anomalies** pour cibler, visualiser et corriger variable par variable.")
    else:
        st.success("‚úÖ Aucun outlier d√©tect√© avec cette r√®gle globale.")
    st.divider()

    # ---------- Colonnes probl√©matiques (constantes & >50% NA) ----------
    st.markdown("### üßä Colonnes constantes & >50% NA")
    const_cols = detect_constant_columns(df)
    na_cols    = get_columns_above_threshold(df, 0.5)
    if const_cols or na_cols:
        candidates = sorted(set(const_cols) | set(na_cols))
        st.warning(f"‚ö†Ô∏è Colonnes candidates √† suppression ({len(candidates)}) :")
        st.code(", ".join(candidates))
    else:
        st.info("Rien √† signaler selon ces r√®gles simples.")
    st.divider()

    # ---------- Correction automatique (semi-auto, confirm√©e) ----------
    st.markdown("### üßº Correction automatique des colonnes probl√©matiques")
    if st.button("Corriger maintenant", key="qual_fix"):
        try:
            to_drop = sorted(set(const_cols) | set(na_cols))
            if not to_drop:
                st.info("Aucune colonne √† supprimer selon les r√®gles.")
            else:
                st.markdown("### Colonnes √† supprimer :")
                st.code(", ".join(to_drop))
                if st.button("Confirmer la suppression", key="qual_fix_confirm"):
                    # Modif in-place + mise √† jour du state
                    df.drop(columns=to_drop, inplace=True, errors="ignore")
                    st.session_state["df"] = df
                    save_snapshot(df, suffix="qualite_cleaned")
                    log_action("qualite_auto_fix", f"{len(to_drop)} colonnes supprim√©es")
                    st.success(f"‚úÖ Correction appliqu√©e : {len(to_drop)} colonnes supprim√©es.")
        except Exception as e:
            st.error(f"‚ùå Erreur pendant la correction : {e}")
    st.divider()

    # ---------- Validation √©tape EDA ----------
    validate_step_button("stats", context_prefix="qualite_")

    # ---------- Footer ----------
    show_footer(
        author="Xavier Rousseau",
        site_url="https://xavrousseau.github.io/",
        version="1.0",
    )
