# ============================================================
# Fichier : qualite.py
# Objectif : √âvaluation de la qualit√© des donn√©es (score + anomalies)
# Version : unifi√©e (utilise utils.eda_utils), barre compacte, √©tape EDA "stats"
# ============================================================

import pandas as pd
import numpy as np
import plotly.express as px
import streamlit as st

from utils.steps import EDA_STEPS
from utils.eda_utils import (
    detect_constant_columns,
    detect_low_variance_columns,        # dispo si tu veux l'ajouter aux r√®gles
    get_columns_above_threshold,
    detect_outliers,
)
from utils.snapshot_utils import save_snapshot
from utils.log_utils import log_action
from utils.filters import get_active_dataframe
from utils.ui_utils import show_header_image_safe, show_icon_header


def run_qualite():
    # === En-t√™te + barre de progression ======================
    show_header_image_safe("bg_pagoda_moon.png")
    show_icon_header("üß™", "Qualit√©", "D√©tection de colonnes suspectes, doublons, placeholders, outliers‚Ä¶")

    # === DataFrame actif =====================================
    df, nom = get_active_dataframe()
    if df is None or df.empty:
        st.warning("‚ùå Aucun fichier actif ou fichier vide. S√©lectionne un fichier dans l‚Äôonglet Fichiers.")
        return

    # === Score global (simple et explicite) ==================
    st.markdown("### üå∏ Score global de qualit√©")
    na_penalty   = df.isna().mean().mean() * 40                     # p√©nalise les NA moyens
    dup_penalty  = 20 if df.duplicated().any() else 0               # p√©nalise s'il y a des doublons
    const_penalty= (df.nunique() <= 1).sum() / max(1, df.shape[1]) * 40
    score = max(0, int(100 - (na_penalty + dup_penalty + const_penalty)))
    st.subheader(f"üåü **{score} / 100**")
    st.divider()

    # === R√©sum√© des anomalies cl√©s ===========================
    st.markdown("### üßæ R√©sum√© des anomalies")
    nb_const = int((df.nunique() <= 1).sum())
    nb_na50  = int((df.isna().mean() > 0.5).sum())
    nb_dup   = int(df.duplicated().sum())

    st.markdown(
        f"- üîÅ **{nb_dup} lignes dupliqu√©es**  \n"
        f"- üü® **{nb_na50} colonnes avec >50% de NA**  \n"
        f"- üßä **{nb_const} colonnes constantes**"
    )
    st.divider()

    # === Heatmap NA (optionnelle) ============================
    if st.checkbox("üìä Afficher la heatmap des NA"):
        fig = px.imshow(
            df.isna(),
            aspect="auto",
            color_continuous_scale="Blues",
            title="Carte des valeurs manquantes",
        )
        st.plotly_chart(fig, use_container_width=True)
    st.divider()

    # === V√©rifications suppl√©mentaires =======================
    st.markdown("### ü©∫ V√©rifications suppl√©mentaires")

    # Colonnes 'object' qui semblent num√©riques
    suspect_numeric_as_str = [
        col for col in df.select_dtypes(include="object").columns
        if df[col].astype(str).str.replace(".", "", regex=False).str.replace(",", "", regex=False).str.isnumeric().mean() > 0.8
    ]
    if suspect_numeric_as_str:
        st.warning("üî¢ Colonnes `object` contenant majoritairement des chiffres :")
        st.code(", ".join(suspect_numeric_as_str))

    # Noms de colonnes suspects
    suspect_names = [col for col in df.columns if col.startswith("Unnamed") or "id" in col.lower()]
    if suspect_names:
        st.warning("üìõ Noms de colonnes suspects :")
        st.code(", ".join(suspect_names))

    # Valeurs placeholders communes
    placeholder_values = {"unknown", "n/a", "na", "undefined", "none", "missing", "?"}
    placeholder_hits = {
        col: int(df[col].astype(str).str.lower().isin(placeholder_values).sum())
        for col in df.columns
    }
    placeholder_hits = {k: v for k, v in placeholder_hits.items() if v > 0}
    if placeholder_hits:
        st.warning("‚ùì Valeurs placeholders d√©tect√©es :")
        st.dataframe(pd.DataFrame.from_dict(placeholder_hits, orient="index", columns=["Occurrences"]))

    st.divider()

    # === Outliers (d√©tection commune) ========================
    st.markdown("### üìâ Valeurs extr√™mes (Z-score > 3, m√©thode commune)")
    num_cols = df.select_dtypes(include="number").columns.tolist()
    out_counts = {}
    for col in num_cols:
        s = df[col].dropna()
        if s.empty or s.std(ddof=0) == 0:
            continue
        try:
            out_idx_or_df = detect_outliers(df[[col]], method="zscore", threshold=3.0)
            if isinstance(out_idx_or_df, pd.DataFrame):
                out_counts[col] = int(out_idx_or_df.shape[0])
            else:  # Index ou liste d‚Äôindex
                out_counts[col] = int(len(out_idx_or_df))
        except Exception:
            # En cas d‚Äôerreur inattendue sur une colonne, on l‚Äôignore dans ce r√©sum√©
            continue

    if out_counts:
        st.warning("üö® Outliers d√©tect√©s :")
        st.dataframe(pd.DataFrame.from_dict(out_counts, orient="index", columns=["Nb outliers"]))
    else:
        st.success("‚úÖ Aucun outlier d√©tect√© avec cette r√®gle globale.")
    st.divider()

    # === Colonnes probl√©matiques identifi√©es =================
    st.markdown("### üßä Colonnes constantes & >50% NA")
    const_cols = detect_constant_columns(df)
    na_cols    = get_columns_above_threshold(df, 0.5)   # 50% NA
    if const_cols or na_cols:
        st.warning(f"‚ö†Ô∏è Colonnes candidates √† suppression ({len(set(const_cols) | set(na_cols))}) :")
        st.code(", ".join(sorted(set(const_cols) | set(na_cols))))
    else:
        st.info("Rien √† signaler selon ces r√®gles simples.")
    st.divider()

    # === Correction automatique (r√®gles claires) =============
    st.markdown("### üßº Correction automatique des colonnes probl√©matiques")
    if st.button("Corriger maintenant", key="qual_fix"):
        try:
            to_drop = sorted(set(const_cols) | set(na_cols))
            if not to_drop:
                st.info("Aucune colonne √† supprimer selon les r√®gles (constantes ou >50% NA).")
            else:
                st.markdown("### Colonnes √† supprimer :")
                st.code(", ".join(to_drop))
                if st.button("Confirmer la suppression", key="qual_fix_confirm"):
                    df.drop(columns=to_drop, inplace=True, errors="ignore")
                    st.session_state.df = df
                    save_snapshot(df, suffix="qualite_cleaned")
                    log_action("qualite_auto_fix", f"{len(to_drop)} colonnes supprim√©es")
                    st.success(f"‚úÖ Correction appliqu√©e : {len(to_drop)} colonnes supprim√©es.")
        except Exception as e:
            st.error(f"‚ùå Erreur pendant la correction : {e}")

    st.divider()
