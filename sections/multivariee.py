# ============================================================
# Fichier : sections/multivariee.py
# Objectif : Analyses multivari√©es interactives (PCA & K-means)
# Version  : UI unifi√©e + √©tapes EDA + snapshots & logs
# Auteur   : Xavier Rousseau
# ============================================================

from __future__ import annotations

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
 
from utils.snapshot_utils import save_snapshot
from utils.log_utils import log_action
from utils.filters import get_active_dataframe 
from utils.ui_utils import section_header, show_footer



# =============================== Helpers internes ==============================

def _select_numeric(df: pd.DataFrame) -> pd.DataFrame:
    """
    Retourne un sous-DataFrame num√©rique (float/int) sans NA (listwise),
    pour un usage simple avec PCA/K-means.

    Remarque :
      - On effectue un dropna() pour la clart√© p√©dagogique. Pour de tr√®s
        grands datasets, envisager une imputation en amont dans une autre page.
    """
    num = df.select_dtypes(include=["number"]).copy()
    return num.dropna(axis=0, how="any")


def _standardize(X: pd.DataFrame, with_mean: bool = True, with_std: bool = True) -> tuple[pd.DataFrame, StandardScaler]:
    """
    Standardise les colonnes (Z-score) via StandardScaler (sklearn).

    Retour :
      - X_std : DataFrame standardis√© avec m√™mes index/colonnes
      - scaler : objet StandardScaler pour inversions/exports √©ventuels
    """
    scaler = StandardScaler(with_mean=with_mean, with_std=with_std)
    Z = scaler.fit_transform(X.values)
    X_std = pd.DataFrame(Z, index=X.index, columns=X.columns)
    return X_std, scaler


def _fit_pca(X: pd.DataFrame, n_components: int) -> tuple[PCA, pd.DataFrame, pd.Series, pd.Series]:
    """
    Ajuste une PCA et renvoie :
      - pca          : mod√®le PCA sklearn
      - scores (DF)  : projections (composantes principales)
      - exp_var (%)  : variance expliqu√©e par composante (en %)
      - cum_exp_var (%): cumul de variance expliqu√©e (en %)
    """
    pca = PCA(n_components=n_components, random_state=42)
    T = pca.fit_transform(X.values)
    cols = [f"PC{i+1}" for i in range(n_components)]
    scores = pd.DataFrame(T, index=X.index, columns=cols)
    exp = pd.Series(pca.explained_variance_ratio_ * 100, index=cols, name="Explained Var (%)")
    cum = exp.cumsum().rename("Cumulative (%)")
    return pca, scores, exp, cum


def _fit_kmeans(
    X: pd.DataFrame,
    k: int,
    n_init: int = 10,           # ‚Üê compat versions < 1.4 (au lieu de "auto")
    random_state: int = 42,
) -> tuple[KMeans, np.ndarray, float]:
    """
    Ajuste un K-means et retourne :
      - mod√®le KMeans
      - labels (np.ndarray)
      - silhouette (float) si calculable, sinon NaN
    """
    km = KMeans(n_clusters=k, n_init=n_init, random_state=random_state)
    labels = km.fit_predict(X.values)

    sil = float("nan")
    try:
        # silhouette dispo si au moins 2 clusters non vides et ‚â• 2 observations
        if len(set(labels)) > 1 and X.shape[0] >= 2:
            sil = float(silhouette_score(X.values, labels))
    except Exception:
        pass

    return km, labels, sil



# ================================== Vue =======================================

def run_multivariee() -> None:
    """
    Page ¬´ Analyses multivari√©es ¬ª :

    Modules :
      - PCA (Analyse en Composantes Principales)
        * Standardisation optionnelle
        * Choix du nombre de composantes
        * Scree plot (variance expliqu√©e) + cumul
        * Projection 2D/3D + (mini) biplot chargeings
      - K-means
        * Clustering sur l‚Äôespace standardis√© OU sur l‚Äôespace PCA
        * √âvaluation silhouette, sauvegarde des clusters

    Effets :
      - Les projections et labels sont ajout√©s au DataFrame actif (colonnes 'PC*' et 'cluster_k').
      - Des snapshots sont cr√©√©s pour tracer l‚Äôhistorique.
      - Les actions sont logu√©es.
    """
    # ---------- En-t√™te ----------
    section_header(
        title="Multivari√©e",
        subtitle="PCA pour r√©duire la dimension et K-means pour regrouper les observations.",
        section="multivariee",  # ‚Üê banni√®res : SECTION_BANNERS["multivariee"]
        emoji="",
    )

    # ---------- DataFrame actif ----------
    df, nom = get_active_dataframe()
    if df is None or df.empty:
        st.warning("‚ùå Aucun fichier actif. Importez un fichier via **Chargement**.")
        return

    # ---------- S√©lection des variables & options globales ----------
    st.markdown("### üîß Pr√©paration des donn√©es")
    numeric_df = df.select_dtypes(include=["number"])
    if numeric_df.empty:
        st.error("‚ùå Aucune colonne num√©rique disponible pour l‚Äôanalyse multivari√©e.")
        return

    with st.expander("S√©lection des variables (num√©riques)", expanded=True):
        cols_selected = st.multiselect(
            "Variables √† inclure",
            options=numeric_df.columns.tolist(),
            default=numeric_df.columns.tolist(),
            help="Retirez les variables hors-sujet ou redondantes avant la PCA/K-means."
        )

    if not cols_selected:
        st.info("S√©lectionnez au moins une variable.")
        return

    # Pr√©traitement : imputation douce (par d√©faut) ou dropna listwise
    X_raw = df[cols_selected].copy()
    do_impute = st.checkbox(
        "Imputer les valeurs manquantes (moyenne)",
        value=True,
        help="√âvite de perdre toutes les lignes si des NA sont pr√©sents."
    )

    if do_impute:
        X = X_raw.apply(pd.to_numeric, errors="coerce")

        # Colonnes 100% NA apr√®s coercition -> on les retire
        all_nan_cols = X.columns[X.isna().all()]
        if len(all_nan_cols):
            st.caption("‚ö†Ô∏è Colonnes 100% NA apr√®s coercition supprim√©es : " + ", ".join(map(str, all_nan_cols)))
            X = X.drop(columns=all_nan_cols, errors="ignore")

        # Imputation moyenne (num√©rique uniquement)
        X = X.fillna(X.mean(numeric_only=True))
        dropped = 0
    else:
        X = X_raw.dropna(axis=0, how="any")
        dropped = len(X_raw) - len(X)
        if dropped:
            st.caption(f"‚ÑπÔ∏è {dropped} ligne(s) supprim√©e(s) pour valeurs manquantes sur les variables retenues.")

    # Variables retir√©es par la pr√©paration (ex. 100% NA)
    removed_vars = [c for c in cols_selected if c not in X.columns]
    if removed_vars:
        st.caption("‚ö†Ô∏è Variables retir√©es pendant la pr√©paration : " + ", ".join(map(str, removed_vars)))

    # (Optionnel) Alerte sur les colonnes √† variance nulle (peu utiles en PCA)
    zero_var_cols = X.std(numeric_only=True) == 0
    zero_var_cols = [c for c, z in zero_var_cols.items() if z]
    if zero_var_cols:
        st.caption("‚ÑπÔ∏è Colonnes √† variance nulle (faible apport en PCA) : " + ", ".join(map(str, zero_var_cols)))

    # Garde-fous
    if X.shape[0] == 0 or X.shape[1] == 0:
        st.error("‚ùå Aucune donn√©e exploitable apr√®s pr√©paration. Activez l‚Äôimputation ou r√©duisez la s√©lection.")
        return

    # ============================== PCA =======================================
    st.markdown("## üìâ PCA ‚Äî R√©duction de dimension")

    col_std1, col_std2 = st.columns(2)
    with col_std1:
        do_standardize = st.checkbox("Standardiser (Z-score)", value=True, help="Recommand√© si les √©chelles diff√®rent.")
    with col_std2:
        # n_components <= min(n_samples, n_features)
        max_pcs = int(max(1, min(10, X.shape[0], X.shape[1])))
        n_comp = st.slider(
            "Nombre de composantes",
            min_value=1 if max_pcs == 1 else 2,
            max_value=max_pcs,
            value=min(2, max_pcs),
        )

    # Standardisation robuste
    try:
        X_std, scaler = _standardize(X) if do_standardize else (X.copy(), None)
    except ValueError as e:
        st.error(f"Standardisation impossible : {e}")
        return

    # PCA
    pca, scores, exp, cum = _fit_pca(X_std, n_components=n_comp)


    # Scree plot (variance expliqu√©e)
    scree_df = pd.DataFrame({"Composante": exp.index, "Var (%)": exp.values, "Cumul (%)": cum.values})
    fig_scree = px.bar(scree_df, x="Composante", y="Var (%)", title="Scree plot ‚Äî Variance expliqu√©e par composante")
    fig_scree.add_scatter(x=scree_df["Composante"], y=scree_df["Cumul (%)"], mode="lines+markers", name="Cumul (%)")
    st.plotly_chart(fig_scree, use_container_width=True)
    st.caption(f"Total expliqu√© par {n_comp} composantes : **{cum.iloc[-1]:.2f}%**")

    # Projection 2D/3D
    st.markdown("### üéØ Projection")
    proj_mode = st.radio("Espace de projection", ["2D", "3D"], horizontal=True)
    color_by = st.selectbox("Couleur par", options=["Aucune"] + df.columns.tolist(), index=0)

    proj_df = scores.copy()
    proj_df.index.name = "index"
    if color_by != "Aucune":
        proj_df[color_by] = df.loc[proj_df.index, color_by]

    fig_proj = None
    if proj_mode == "2D":
        if proj_df.shape[1] >= 2:
            fig_proj = px.scatter(
                proj_df, x="PC1", y="PC2",
                color=None if color_by == "Aucune" else color_by,
                hover_data=[proj_df.index],
                title="Projection PCA (PC1 vs PC2)"
            )
        else:
            st.info("‚ÑπÔ∏è Au moins 2 composantes n√©cessaires pour la 2D.")
    else:  # 3D
        if {"PC1","PC2","PC3"}.issubset(proj_df.columns):
            fig_proj = px.scatter_3d(
                proj_df, x="PC1", y="PC2", z="PC3",
                color=None if color_by == "Aucune" else color_by,
                hover_data=[proj_df.index],
                title="Projection PCA (PC1 vs PC2 vs PC3)"
            )
        else:
            st.info("‚ÑπÔ∏è Au moins 3 composantes n√©cessaires pour la 3D.")

    if fig_proj is not None:
        st.plotly_chart(fig_proj, use_container_width=True)

    # (Mini) biplot : charges des variables sur PC1/PC2
    with st.expander("üìé Biplot (charges variables sur PC1/PC2)", expanded=False):
        if n_comp >= 2:
            # ‚ö†Ô∏è Utiliser les colonnes r√©ellement pass√©es √† la PCA (apr√®s nettoyage)
            feature_names = list(X_std.columns)  # pas cols_selected !
            comps = pca.components_[:2, :]       # shape = (2, n_features)

            # Garde-fou (au cas o√π) : s'assurer que le nb de features colle
            if comps.shape[1] != len(feature_names):
                min_feats = min(comps.shape[1], len(feature_names))
                comps = comps[:, :min_feats]
                feature_names = feature_names[:min_feats]

            loadings = pd.DataFrame(comps.T, index=feature_names, columns=["PC1", "PC2"])

            fig_load = px.scatter(
                loadings, x="PC1", y="PC2",
                text=loadings.index,
                title="Charges (PC1/PC2)"
            )
            fig_load.update_traces(textposition="top center")
            st.plotly_chart(fig_load, use_container_width=True)
            st.caption("Les charges indiquent la contribution directionnelle des variables aux composantes.")
        else:
            st.info("‚ÑπÔ∏è Biplot indisponible avec moins de 2 composantes.")


    # ============================== K-MEANS ====================================
    # ‚úÖ Section K-means (UI) robuste + typage Int64 des labels
    # ============================== K-MEANS ====================================
    st.markdown("## üß≠ K-means ‚Äî Regroupements")

    use_space = st.radio(
        "Espace de clustering",
        ["Donn√©es standardis√©es", "Scores PCA"],
        horizontal=True,
        help="Le clustering sur les scores PCA peut r√©duire le bruit et acc√©l√©rer."
    )
    k = st.slider("Nombre de clusters (k)", min_value=2, max_value=10, value=3)

    # Espace choisi
    if use_space == "Donn√©es standardis√©es":
        X_cluster = X_std
        space_label = "std"
    else:
        X_cluster = scores  # n_comp colonnes
        space_label = f"pca{n_comp}"

    # Ajustement K-means
    if st.button("üöÄ Lancer le clustering K-means"):
        # Garde-fous avant fit
        if X_cluster is None or X_cluster.shape[0] == 0:
            st.error("‚ùå Aucune observation disponible pour le clustering.")
        elif X_cluster.shape[0] < k:
            st.error(f"‚ùå {X_cluster.shape[0]} observation(s) seulement, inf√©rieur √† k={k}. R√©duisez k.")
        else:
            try:
                km, labels, sil = _fit_kmeans(X_cluster, k=k)
                st.success(f"‚úÖ Clustering termin√©. Silhouette = {sil:.3f}" if np.isfinite(sil) else "‚úÖ Clustering termin√©.")

                # Ajouter les labels au DF actif (index align√©) avec dtype nullable
                label_col = f"cluster_k{k}_{space_label}"
                df.loc[X_cluster.index, label_col] = pd.Series(labels, index=X_cluster.index, dtype="Int64")
                st.session_state["df"] = df

                # Visualisation : 2D si possible
                if use_space == "Scores PCA":
                    vis_df = scores.copy()
                    can_plot = vis_df.shape[1] >= 2
                else:
                    # Si pas de PCA affichable, cr√©e une 2D de visu via PCA(2) si ‚â•2 features
                    if X_std.shape[1] >= 2:
                        _, vis_scores, _, _ = _fit_pca(X_std, n_components=2)
                        vis_df = vis_scores.copy()
                        can_plot = True
                    else:
                        can_plot = False

                if can_plot:
                    vis_df[label_col] = pd.Series(labels, index=X_cluster.index)
                    fig_clusters = px.scatter(
                        vis_df,
                        x=vis_df.columns[0], y=vis_df.columns[1],
                        color=label_col,
                        hover_data=[vis_df.index],
                        title=f"Clusters K={k} ({'PCA' if use_space=='Scores PCA' else 'PCA(2) pour visualisation'})"
                    )
                    st.plotly_chart(fig_clusters, use_container_width=True)
                else:
                    st.info("Visualisation 2D indisponible (moins de deux dimensions).")

                # Sauvegarde (snapshot des labels uniquement)
                save_snapshot(df.loc[X_cluster.index, [label_col]], suffix=label_col)
                log_action("kmeans_fit", f"k={k} on {space_label}, silhouette={sil:.3f}")
            except Exception as e:
                st.error(f"‚ùå Erreur K-means : {e}")


    # ---------- Footer ----------
    show_footer(
        author="Xavier Rousseau",
        site_url="https://xavrousseau.github.io/",
        version="1.0",
    )
