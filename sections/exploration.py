# ============================================================
# Fichier : sections/exploration.py
# Objectif : Analyse exploratoire avancÃ©e et interactive
# Version  : harmonisÃ©e avec lâ€™UI unifiÃ©e et les Ã©tapes EDA
# Auteur   : Xavier Rousseau
# ============================================================

from __future__ import annotations

import pandas as pd
import plotly.express as px
import streamlit as st

from utils.steps import EDA_STEPS
from utils.snapshot_utils import save_snapshot
from utils.eda_utils import (
    summarize_dataframe,
    plot_missing_values,
    detect_constant_columns,
    detect_low_variance_columns,
    get_columns_above_threshold,
    detect_outliers,
    compute_correlation_matrix,
)
from utils.log_utils import log_action
from utils.filters import validate_step_button, get_active_dataframe
from utils.ui_utils import section_header, show_eda_progress, show_footer
from utils.sql_bridge import expose_to_sql_lab


def run_exploration() -> None:
    """
    Tableau de bord dâ€™EDA (Analyse de DonnÃ©es Exploratoire).

    Onglets :
      1) Types         â€” rÃ©sumÃ© structurel + dtypes par colonne.
      2) Manquants     â€” visualisation NA, suppression au-dessus dâ€™un seuil.
      3) Statistiques  â€” describe() complet + taux NA global.
      4) Distributions â€” histogramme interactif + asymÃ©trie (skew).
      5) Outliers      â€” dÃ©tection simple (IQR ou Z-score) par variable.
      6) CorrÃ©lations  â€” matrice corrÃ©lation (Pearson, Spearman, Kendall).
      7) Nettoyage autoâ€” drop de colonnes constantes, quasi-constantes, NA Ã©levÃ©s.

    Effets :
      - Certaines actions modifient le DataFrame actif in-place
        (suppression de colonnes), mettent Ã  jour `st.session_state["df"]`,
        crÃ©ent un snapshot, et loguent lâ€™action.

    Notes UX/Perf :
      - Les affichages tabulaires sont bornÃ©s par lâ€™UI Streamlit (dataframe).
      - Les graphiques utilisent Plotly pour lâ€™interactivitÃ© et lâ€™accessibilitÃ©.
      - Les seuils (NA, variance) sont exposÃ©s Ã  lâ€™utilisateur quand pertinent.
    """
    # ---------- En-tÃªte unifiÃ© ----------
    section_header(
        title="Exploration",
        subtitle="Analyse des types, valeurs manquantes, distributions, outliers et corrÃ©lations.",
        section="exploration",  # â† utilise SECTION_BANNERS["exploration"]
        emoji="",
    )

    # ---------- Barre de progression ----------
    show_eda_progress(EDA_STEPS, compact=True, single_row=True)

    # ---------- Fichier actif ----------
    df, nom = get_active_dataframe()
    if df is None:
        st.warning("âŒ Aucun fichier actif. Importez un fichier via lâ€™onglet **Chargement**.")
        return


    # Colonnes numÃ©riques dÃ©tectÃ©es (utile dans plusieurs onglets)
    num_cols = df.select_dtypes(include="number").columns.tolist()

    # ---------- Navigation par onglets ----------
    tabs = st.tabs([
        "ğŸ§¬ Types", "ğŸ©¹ Manquants", "ğŸ“ˆ Statistiques",
        "ğŸ“Š Distributions", "ğŸš¨ Outliers", "ğŸ”— CorrÃ©lations", "ğŸ§¼ Nettoyage auto"
    ])

    # ---------------------------------------------------------
    # ğŸ§¬ Types
    # ---------------------------------------------------------
    with tabs[0]:
        st.subheader("ğŸ§¬ Types de colonnes")

        # RÃ©sumÃ© structurel (dÃ©lÃ©guÃ© Ã  utils.eda_utils.summarize_dataframe)
        summary = summarize_dataframe(df)
        st.dataframe(summary, use_container_width=True)

        with st.expander("ğŸ” DÃ©tails des types par colonne", expanded=False):
            dtypes_df = pd.DataFrame({
                "Colonne": df.columns,
                "dtype": [str(t) for t in df.dtypes],
            })
            st.dataframe(dtypes_df, use_container_width=True)

        st.info(
            "â„¹ï¸ Ceci est un **aperÃ§u**. Pour corriger finement les types "
            "(conversions, datetime, boolÃ©ens, etc.), utilisez la page **Typage**."
        )

        validate_step_button("typing", context_prefix="exploration_")

    # ---------------------------------------------------------
    # ğŸ©¹ Valeurs manquantes
    # ---------------------------------------------------------
    with tabs[1]:
        st.subheader("ğŸ©¹ Analyse des valeurs manquantes")

        # Slider en pourcentage entier (0 â†’ 100 %), puis conversion en proportion [0,1]
        seuil_pct = st.slider(
            "ğŸ¯ Seuil de suppression (%)",
            min_value=0, max_value=100, value=50, step=1,
            help="Colonnes dont le pourcentage de valeurs manquantes est supÃ©rieur Ã  ce seuil seront candidates Ã  la suppression."
        )
        threshold = seuil_pct / 100.0  # â† proportion pour le calcul

        # Heatmap/bar manquants
        fig = plot_missing_values(df)
        if fig:
            st.plotly_chart(fig, use_container_width=True)

        # Colonnes dÃ©passant le seuil (en proportion)
        cols_na = get_columns_above_threshold(df, threshold)

        if cols_na:
            st.warning(f"{len(cols_na)} colonnes dÃ©passent {seuil_pct:.0f}% de NA.")
            selected = st.multiselect(
                "Colonnes Ã  supprimer",
                options=cols_na,
                default=cols_na,
                help="DÃ©sÃ©lectionnez ce que vous souhaitez conserver malgrÃ© tout."
            )
            if selected and st.button("ğŸ—‘ï¸ Supprimer sÃ©lection"):
                # Modif in-place + mise Ã  jour du state
                df.drop(columns=selected, inplace=True, errors="ignore")
                st.session_state["df"] = df
                save_snapshot(df, "missing_dropped")
                expose_to_sql_lab(f"{nom}__missing_dropped", df, make_active=True)
                log_action("missing_cleanup", f"{len(selected)} colonnes supprimÃ©es (> {seuil_pct:.0f}% NA)")
                st.success("âœ… Colonnes supprimÃ©es avec succÃ¨s.")
        else:
            st.info("âœ… Aucune colonne ne dÃ©passe le seuil dÃ©fini.")

        validate_step_button("missing", context_prefix="exploration_")
    # ---------------------------------------------------------
    # ğŸ“ˆ Statistiques descriptives
    # ---------------------------------------------------------
    with tabs[2]:
        st.subheader("ğŸ“ˆ Statistiques descriptives")

        # describe(include="all") essaye de couvrir tous les types.
        # datetime_is_numeric=True (pandas >= 1.5) : stats numÃ©riques sur dates (comptage, min, max) utiles.
        try:
            stats = df.describe(include="all", datetime_is_numeric=True).T
        except TypeError:
            # Compat anciennes versions de pandas
            stats = df.describe(include="all").T

        st.dataframe(stats, use_container_width=True)

        pct_missing = df.isna().mean().mean() * 100
        st.info(f"Taux global de valeurs manquantes : **{pct_missing:.2f}%**")

        validate_step_button("stats", context_prefix="exploration_")


    # ---------------------------------------------------------
    # ğŸ“Š Distributions
    # ---------------------------------------------------------
    with tabs[3]:
        st.subheader("ğŸ“Š Distribution des variables numÃ©riques")

        if not num_cols:
            st.warning("âš ï¸ Aucune variable numÃ©rique dÃ©tectÃ©e.")
        else:
            col = st.selectbox("ğŸ“ˆ Variable Ã  visualiser", num_cols, key="hist_col")
            # Histogramme simple (nbins=40 : compromis lisibilitÃ© / lissage)
            fig = px.histogram(df, x=col, nbins=40, title=f"Distribution de {col}")
            st.plotly_chart(fig, use_container_width=True)

            # Skewness (asymÃ©trie) : indicateur rapide de symÃ©trie de la distribution
            skew = df[col].skew()
            skew_type = (
                "symÃ©trique" if abs(skew) < 0.5
                else "asymÃ©trique positive" if skew > 0
                else "asymÃ©trique nÃ©gative"
            )
            st.info(f"AsymÃ©trie de `{col}` : **{skew:.2f}** â†’ *{skew_type}*")

        validate_step_button("distributions", context_prefix="exploration_")


    # ---------------------------------------------------------
    # ğŸš¨ Outliers
    # ---------------------------------------------------------
    with tabs[4]:
        st.subheader("ğŸš¨ DÃ©tection dâ€™outliers")

        if not num_cols:
            st.warning("âš ï¸ Pas de variable numÃ©rique pour dÃ©tecter des outliers.")
        else:
            method = st.radio(
                "MÃ©thode",
                ["iqr", "zscore"],
                horizontal=True,
                help=(
                    "IQR : valeurs hors [Q1 - 1.5*IQR ; Q3 + 1.5*IQR]. "
                    "Z-score : |z| au-delÃ  dâ€™un seuil (gÃ©nÃ©ralement 3)."
                ),
            )
            col = st.selectbox("ğŸ” Variable Ã  analyser", num_cols, key="outliers_col")

            # On rÃ©cupÃ¨re ses index pour rÃ©-extraire TOUTES les colonnes depuis le DF d'origine.
            out_idx = detect_outliers(df[[col]], method=method).index
            outliers = df.loc[out_idx].copy()

            st.info(f"{len(outliers)} outliers dÃ©tectÃ©s sur `{col}` (mÃ©thode {method}).")
            st.dataframe(outliers.head(10), use_container_width=True)

            if st.button("ğŸ’¾ Sauvegarder les outliers dÃ©tectÃ©s"):
                save_snapshot(outliers, suffix=f"outliers_{method}_{col}")
                log_action("outliers_detected", f"{len(outliers)} sur {col} ({method})")
                expose_to_sql_lab(f"{nom}__outliers_{method}_{col}", outliers)
                st.success("âœ… Snapshot des outliers enregistrÃ©.")

        validate_step_button("extremes", context_prefix="exploration_")


    # ---------------------------------------------------------
    # ğŸ”— CorrÃ©lations
    # ---------------------------------------------------------
    with tabs[5]:
        st.subheader("ğŸ”— CorrÃ©lations")

        if len(num_cols) < 2:
            st.warning("âš ï¸ Pas assez de variables numÃ©riques pour une corrÃ©lation.")
        else:
            method = st.radio(
                "MÃ©thode",
                ["pearson", "spearman", "kendall"],
                horizontal=True,
                help=(
                    "Pearson : corrÃ©lation linÃ©aire (variables quantitatives). "
                    "Spearman : rangs (monotone, robuste aux non-linÃ©aritÃ©s). "
                    "Kendall : rangs, plus conservateur (petits Ã©chantillons)."
                ),
            )
            corr = compute_correlation_matrix(df[num_cols], method=method)

            if corr.empty:
                st.info(f"Aucune corrÃ©lation exploitable pour **{method}**.")
            else:
                # Heatmap Ã  gamme [-1, 1], Ã©tiquette de cellule avec 2 dÃ©cimales
                fig = px.imshow(
                    corr,
                    text_auto=".2f",
                    aspect="auto",
                    zmin=-1, zmax=1,
                    color_continuous_scale="RdBu_r",
                    title=f"Matrice de corrÃ©lation ({method})",
                )
                fig.update_layout(margin=dict(t=40, l=20, r=20, b=60))
                st.plotly_chart(fig, use_container_width=True)

        validate_step_button("correlations", context_prefix="exploration_")


    # ---------------------------------------------------------
    # ğŸ§¼ Nettoyage auto
    # ---------------------------------------------------------
    with tabs[6]:
        st.subheader("ğŸ§¼ Nettoyage automatique")

        # RÃ¨gles simples : constantes, faible variance, forte proportion de NA
        const_cols = detect_constant_columns(df)
        low_var = detect_low_variance_columns(df)
        na_cols = get_columns_above_threshold(df, 0.5)  # 50% NA par dÃ©faut
        all_to_drop = sorted(set(const_cols + low_var + na_cols))

        st.markdown(f"ğŸ” Colonnes identifiÃ©es : **{len(all_to_drop)}**")

        if all_to_drop:
            with st.expander("Voir les colonnes candidates"):
                st.write(all_to_drop)

            if st.button("ğŸ§¹ Appliquer le nettoyage auto"):
                df.drop(columns=all_to_drop, inplace=True, errors="ignore")
                st.session_state["df"] = df
                save_snapshot(df, suffix="auto_cleaned")
                expose_to_sql_lab(f"{nom}__auto_cleaned", df, make_active=True)
                log_action("auto_cleanup", f"{len(all_to_drop)} colonnes supprimÃ©es (const/faible var/NA Ã©levÃ©s)")
                st.success("âœ… Nettoyage appliquÃ©.")
        else:
            st.info("Rien Ã  nettoyer selon ces rÃ¨gles simples.")

        validate_step_button("cleaning", context_prefix="exploration_")

    
    # ---------------------------------------------------------
    # Footer 
    # ---------------------------------------------------------
    show_footer(
        author="Xavier Rousseau",
        site_url="https://xavrousseau.github.io/",
        version="1.0",
    )
