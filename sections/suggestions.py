# ============================================================
# Fichier : suggestions.py
# Objectif : Identifier les colonnes Ã  encoder ou Ã  vectoriser
# Version : harmonisÃ©e, seuils paramÃ©trables, dÃ©tection robuste
# ============================================================

import re
import pandas as pd
import streamlit as st

from utils.snapshot_utils import save_snapshot
from utils.log_utils import log_action
from utils.filters import get_active_dataframe
from utils.ui_utils import show_header_image_safe, show_icon_header


def _is_identifier(colname: str) -> bool:
    return bool(re.search(r"(?:^|_)(id|uid|uuid|identifiant|code)(?:$|_)", str(colname), flags=re.I))


def _avg_str_len(s: pd.Series) -> float:
    try:
        return float(s.astype("string").str.len().dropna().mean())
    except Exception:
        return 0.0


def run_suggestions():
    show_header_image_safe("bg_night_serenity.png")
    show_icon_header("ğŸ’¡", "Suggestions", "Colonnes discrÃ¨tes Ã  encoder, texte libre Ã  vectoriser")

    df, nom = get_active_dataframe()
    if df is None or df.empty:
        st.warning("âŒ Aucun fichier actif. Importez/sÃ©lectionnez un fichier dans lâ€™onglet Fichiers.")
        return

    with st.expander("âš™ï¸ ParamÃ¨tres (seuils)"):
        col_a, col_b, col_c = st.columns(3)
        cat_encode_max = col_a.number_input("Max modalitÃ©s pour encoder une catÃ©gorie", 2, 200, 50, 1)
        num_discrete_max = col_b.number_input("Max modalitÃ©s pour encoder un numÃ©rique", 2, 200, 10, 1)
        text_vectorize_min = col_c.number_input("Min modalitÃ©s pour vectoriser un texte", 20, 5000, 100, 10)
        id_ratio = st.slider("Seuil dâ€™unicitÃ© pour â€˜identifiantâ€™", 0.5, 1.0, 0.9, 0.05)
        long_text_len = st.slider("Longueur moyenne (texte libre)", 10, 200, 30, 5)

    # --- PrÃ©paration des colonnes (âœ… fix datetimes) ---
    num_cols = df.select_dtypes(include="number").columns.tolist()
    obj_cols = df.select_dtypes(include=["object", "string", "category"]).columns.tolist()
    bool_cols = df.select_dtypes(include=["bool", "boolean"]).columns.tolist()
    dt_cols = df.select_dtypes(include=["datetime", "datetimetz"]).columns.tolist()

    to_encode_num, to_encode_cat, to_vectorize, identifiers = {}, {}, {}, {}
    n = len(df)

    # Identifiants (nom ou unicitÃ© Ã©levÃ©e)
    for col in df.columns:
        uniq = df[col].nunique(dropna=True)
        uniq_ratio = (uniq / n) if n else 0
        if _is_identifier(col) or uniq_ratio >= id_ratio:
            identifiers[col] = "ğŸªª Identifiant (unicitÃ© Ã©levÃ©e / nom)"

    ignore = set(bool_cols) | set(dt_cols) | set(identifiers.keys())

    # NumÃ©riques discrets
    for col in [c for c in num_cols if c not in ignore]:
        uniq = int(df[col].nunique(dropna=True))
        if 2 <= uniq <= num_discrete_max and (uniq / n if n else 0) < id_ratio:
            to_encode_num[col] = f"ğŸ”¢ NumÃ©rique discret (modalitÃ©s={uniq}) â€” Ã  encoder"

    # CatÃ©gories vs texte libre
    for col in [c for c in obj_cols if c not in ignore]:
        uniq = int(df[col].nunique(dropna=True))
        avg_len = _avg_str_len(df[col])
        if uniq <= cat_encode_max:
            to_encode_cat[col] = f"ğŸ·ï¸ CatÃ©gorie (modalitÃ©s={uniq}) â€” Ã  encoder"
        elif uniq >= text_vectorize_min or avg_len >= long_text_len:
            to_vectorize[col] = f"ğŸ“ Texte libre (modalitÃ©s={uniq}, lenâ‰ˆ{avg_len:.0f}) â€” Ã  vectoriser"

    st.markdown("### ğŸ” Suggestions dÃ©tectÃ©es")
    any_sugg = False

    if identifiers:
        any_sugg = True
        st.markdown("#### ğŸªª Identifiants (Ã  exclure des features)")
        st.dataframe(pd.DataFrame.from_dict(identifiers, orient="index", columns=["Raison"]), use_container_width=True)

    if to_encode_num:
        any_sugg = True
        st.markdown("#### ğŸ”¢ NumÃ©riques discrets â€” Ã  encoder")
        st.dataframe(pd.DataFrame.from_dict(to_encode_num, orient="index", columns=["Suggestion"]), use_container_width=True)

    if to_encode_cat:
        any_sugg = True
        st.markdown("#### ğŸ·ï¸ CatÃ©gories â€” Ã  encoder")
        st.dataframe(pd.DataFrame.from_dict(to_encode_cat, orient="index", columns=["Suggestion"]), use_container_width=True)

    if to_vectorize:
        any_sugg = True
        st.markdown("#### ğŸ“ Texte libre â€” Ã  vectoriser")
        st.dataframe(pd.DataFrame.from_dict(to_vectorize, orient="index", columns=["Suggestion"]), use_container_width=True)

    if not any_sugg:
        st.success("âœ… Aucune colonne Ã  encoder/vectoriser selon ces rÃ¨gles.")

    st.markdown("### ğŸ“Š RÃ©sumÃ©")
    c1, c2, c3 = st.columns(3)
    c1.metric("Ã€ encoder (num)", len(to_encode_num))
    c2.metric("Ã€ encoder (cat)", len(to_encode_cat))
    c3.metric("Ã€ vectoriser (texte)", len(to_vectorize))

    st.divider()

    # Suppression optionnelle du texte libre
    to_drop = list(to_vectorize.keys())
    if to_drop:
        st.markdown("### ğŸ—‘ï¸ Colonnes candidates Ã  suppression (texte libre / haute cardinalitÃ©)")
        with st.expander("ğŸ” DÃ©tails des colonnes concernÃ©es"):
            st.code(", ".join(to_drop))
        if st.button("ğŸš® PrÃ©parer la suppression des colonnes", key="sugg_drop_prepare"):
            st.warning(
                f"Vous Ãªtes sur le point de supprimer {len(to_drop)} colonne(s) de texte libre. "
                "Cela **ne crÃ©e pas** de vectorisation automatique."
            )
            if st.button("âœ… Confirmer la suppression", key="sugg_drop_confirm"):
                try:
                    df.drop(columns=to_drop, inplace=True, errors="ignore")
                    st.session_state.df = df
                    save_snapshot(df, suffix="suggestions_cleaned")
                    log_action("suggestions_cleanup", f"{len(to_drop)} colonnes supprimÃ©es (texte libre)")
                    st.success("âœ… Colonnes supprimÃ©es. Snapshot sauvegardÃ© (CSV).")
                except Exception as e:
                    st.error(f"âŒ Erreur pendant la suppression : {e}")
    else:
        st.info("Aucune colonne candidate Ã  suppression automatique selon ces rÃ¨gles.")
