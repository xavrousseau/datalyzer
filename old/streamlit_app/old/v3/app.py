# =============================================================================
# ğŸ“¦ IMPORTATION DES LIBRAIRIES
# =============================================================================

import streamlit as st       # Pour crÃ©er l'application web interactive
import pandas as pd          # Pour la manipulation de donnÃ©es
import plotly.express as px  # Pour les visualisations interactives
import numpy as np
from scipy.stats import zscore
import csv                   # Pour la dÃ©tection du sÃ©parateur dans les CSV/TXT
from io import StringIO, BytesIO  # Pour manipuler les flux de donnÃ©es

import sys                   # Pour les interactions systÃ¨me (ex: monitoring)
import psutil                # Pour l'analyse de la mÃ©moire

# Importation des fonctions utilitaires pour l'EDA
from eda_utils import (
    detect_variable_types,         # DÃ©tecte les types de variables
    compute_correlation_matrix,    # Calcule la matrice de corrÃ©lation
    detect_outliers_iqr,           # DÃ©tecte les outliers via la mÃ©thode IQR
    detect_constant_columns,       # DÃ©tecte les colonnes constantes
    detect_low_variance_columns,   # DÃ©tecte les colonnes Ã  faible variance
    encode_categorical,            # Encodage des variables catÃ©gorielles (OneHot ou Ordinal)
    plot_missing_values,           # Trace le graphique des valeurs manquantes
    get_columns_above_threshold,   # Liste les colonnes avec un taux de NA supÃ©rieur au seuil
    drop_missing_columns           # Supprime les colonnes trop incomplÃ¨tes
)

# Importation d'une fonction pour enregistrer les transformations appliquÃ©es
from log_utils import log_transformation

# =============================================================================
# ğŸ¨ CONFIGURATION GLOBALE DE Lâ€™APP
# =============================================================================

st.set_page_config(
    page_title="EDA Explorer â€“ Analyse exploratoire de donnÃ©es",
    layout="wide"
)

# Insertion de styles CSS personnalisÃ©s pour les Ã©lÃ©ments de l'application
st.markdown("""
    <style>
        .stButton>button {
            color: white;
            background: #0099cc;
        }
        .stDownloadButton>button {
            background-color: #28a745;
            color: white;
        }
        .stSlider>div {
            background-color: #f0f0f5;
        }
    </style>
""", unsafe_allow_html=True)

# =============================================================================
# ğŸ§­ BARRE DE NAVIGATION
# =============================================================================

# Menu latÃ©ral pour naviguer entre les sections de l'application
section = st.sidebar.radio("ğŸ§­ Navigation", [
    "ğŸ“‚ Chargement",
    "ğŸ” Analyse exploratoire",
    "ğŸ“Š Analyse catÃ©gorielle",
    "ğŸ¯ Analyse variable cible",
    "ğŸ’¾ Export"
])

# Initialisation des variables globales : le DataFrame et le fichier uploadÃ©
# Affiche un avertissement global si aucun fichier n'est chargÃ©
uploaded_file = st.session_state.get("uploaded_file")

if section != "ğŸ“‚ Chargement" and uploaded_file is None:
    st.warning("ğŸ“‚ Veuillez dâ€™abord charger un fichier via la section 'ğŸ“‚ Chargement'.")
    st.stop()
# =============================================================================
# ğŸ“‚ 1. Chargement du fichier (Accueil)
# =============================================================================

if section == "ğŸ“‚ Chargement":
    st.title("ğŸ“Š EDA Explorer â€“ Application d'analyse exploratoire de donnÃ©es")
    st.markdown("---")

    st.subheader("ğŸ“‚ Chargement du fichier")
    st.info("ğŸ“¦ Vous pouvez importer un fichier jusquâ€™Ã  **200 Mo** (formats supportÃ©s : CSV, TXT, JSON, XLSX, Parquet).")

    # Composant dâ€™upload
    uploaded_file = st.file_uploader("Choisissez un fichier", type=["csv", "txt", "json", "xlsx", "parquet"])

    if uploaded_file:
        # Sauvegarde du fichier uploadÃ© dans la session pour les prochaines sections
        st.session_state["uploaded_file"] = uploaded_file
        file_extension = uploaded_file.name.split(".")[-1].lower()
        st.info(f"ğŸ“„ Fichier sÃ©lectionnÃ© : `{uploaded_file.name}`")

        try:
            # Pour Ã©viter les problÃ¨mes liÃ©s Ã  la position du curseur, on se replace au dÃ©but
            uploaded_file.seek(0)
            if file_extension in ["csv", "txt"]:
                raw_text = uploaded_file.read().decode("utf-8", errors="ignore")
                # DÃ©tection automatique du sÃ©parateur grÃ¢ce Ã  csv.Sniffer
                detected_sep = csv.Sniffer().sniff(raw_text[:2048]).delimiter
                st.success(f"âœ… SÃ©parateur dÃ©tectÃ© automatiquement : `{detected_sep}`")
                df = pd.read_csv(StringIO(raw_text), sep=detected_sep)

            elif file_extension == "json":
                uploaded_file.seek(0)
                df = pd.read_json(uploaded_file)

            elif file_extension == "xlsx":
                df = pd.read_excel(uploaded_file)

            elif file_extension == "parquet":
                df = pd.read_parquet(uploaded_file)

        except Exception as e:
            st.error(f"âŒ Erreur de lecture : {e}")

        # AperÃ§u si tout sâ€™est bien passÃ©
        if df is not None:
            st.success("âœ… Fichier chargÃ© avec succÃ¨s.")
            # Sauvegarde du DataFrame dans la session pour Ã©viter de le recharger
            st.session_state.df = df
            max_rows = st.radio("Nombre de lignes Ã  afficher :", [5, 10, 20, 50, 100], horizontal=True)
            col1, col2 = st.columns(2)
            col1.metric("Lignes", f"{df.shape[0]:,}".replace(",", "â€¯"))
            col2.metric("Colonnes", f"{df.shape[1]:,}".replace(",", "â€¯"))
            st.dataframe(df.head(max_rows), use_container_width=True)

# =============================================================================
# ğŸ” 2. Analyse exploratoire (EDA)
# =============================================================================

elif section == "ğŸ” Analyse exploratoire" and uploaded_file:
    # RÃ©cupÃ©ration du DataFrame depuis la session si dÃ©jÃ  chargÃ©,
    # sinon on le recharge Ã  partir du fichier uploadÃ©.
    if "df" not in st.session_state:
        uploaded_file.seek(0)  # Remise Ã  zÃ©ro du curseur pour une lecture correcte
        file_extension = uploaded_file.name.split(".")[-1].lower()
        if file_extension in ["csv", "txt"]:
            raw_text = uploaded_file.read().decode("utf-8", errors="ignore")
            sep = csv.Sniffer().sniff(raw_text[:2048]).delimiter
            df = pd.read_csv(StringIO(raw_text), sep=sep)
        elif file_extension == "json":
            uploaded_file.seek(0)
            df = pd.read_json(uploaded_file)
        elif file_extension == "xlsx":
            df = pd.read_excel(uploaded_file)
        elif file_extension == "parquet":
            df = pd.read_parquet(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("ğŸ” Analyse exploratoire")
    # CrÃ©ation des onglets pour organiser les analyses
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "ğŸ“Œ Types de variables",
        "ğŸ“‰ Valeurs manquantes",
        "ğŸ“ˆ Histogrammes",
        "ğŸš¨ Outliers",
        "ğŸ§¹ Nettoyage auto",
        "ğŸ§¼ Nettoyage manuel",
        "ğŸ“ Stats descriptives",
        "ğŸ§¬ CorrÃ©lations avancÃ©es"
    ])
    # -------------------------------------------------------------------------
    # Onglet 1 : Types de variables
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### ğŸ“Œ Types de variables dÃ©tectÃ©es")
        st.info("AperÃ§u des colonnes avec type dÃ©tectÃ©, nombre de valeurs uniques, valeurs manquantes et exemple.")
        summary = pd.DataFrame({
            "Nom de la colonne": df.columns,
            "Type pandas": df.dtypes.astype(str),
            "Nb valeurs uniques": df.nunique(),
            "% valeurs manquantes": (df.isna().mean() * 100).round(1).astype(str) + "â€¯%",
            "Exemple de valeur": [
                df[col].dropna().astype(str).unique()[0] if df[col].dropna().shape[0] > 0 else "â€”"
                for col in df.columns
            ]
        }).sort_values("Type pandas")
        st.dataframe(summary, use_container_width=True, height=500)

    # -------------------------------------------------------------------------
    # Onglet 2 : Valeurs manquantes
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### ğŸ“‰ Analyse des valeurs manquantes")
        seuil_pct = st.slider("ğŸ› ï¸ Seuil (%) de valeurs manquantes", 0, 100, 20)
        seuil = seuil_pct / 100
        top_n = st.slider("ğŸ“Œ Top colonnes Ã  afficher", 5, 50, 15)

        fig = plot_missing_values(df, seuil=seuil, top_n=top_n)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("âœ… Aucune valeur manquante.")

        cols_to_remove = get_columns_above_threshold(df, seuil=seuil)
        if cols_to_remove:
            st.warning(f"{len(cols_to_remove)} colonnes dÃ©passent {seuil_pct}% de valeurs manquantes.")
            st.code(", ".join(cols_to_remove))

            if st.checkbox("âŒ Supprimer ces colonnes"):
                df, dropped = drop_missing_columns(df, seuil=seuil)
                log_transformation(f"{len(dropped)} colonnes supprimÃ©es pour seuil {seuil_pct}%")
                st.success(f"{len(dropped)} colonnes supprimÃ©es.")
                st.session_state.df = df

    # -------------------------------------------------------------------------
    # Onglet 3 : Histogrammes des variables numÃ©riques
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### ğŸ“ˆ Distribution des variables numÃ©riques")
        num_cols = df.select_dtypes(include=["number"]).columns.tolist()
        if not num_cols:
            st.warning("âš ï¸ Aucune variable numÃ©rique dÃ©tectÃ©e.")
        else:
            selected_num = st.selectbox("ğŸ“Š Choisissez une variable", num_cols)
            st.plotly_chart(px.histogram(df, x=selected_num), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : DÃ©tection d'outliers (mÃ©thode IQR)
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### ğŸš¨ DÃ©tection d'outliers (mÃ©thode IQR)")
        num_cols = df.select_dtypes(include=["number"]).columns.tolist()
        col = st.selectbox("Variable Ã  analyser", num_cols, key="iqr_col")
        outliers = detect_outliers_iqr(df, col)
        st.write(f"ğŸ” {len(outliers)} outliers dÃ©tectÃ©s.")
        st.dataframe(outliers)

    # -------------------------------------------------------------------------
    # Onglet 5 : Suggestions automatiques de nettoyage
    # -------------------------------------------------------------------------
    with tab5:
        st.markdown("### ğŸ§¹ Suggestions automatiques de nettoyage")
        st.info("Colonnes constantes, faible variance ou fortement manquantes.")
        st.write("ğŸ”¸ Colonnes constantes :", detect_constant_columns(df))
        st.write("ğŸ”¸ Faible variance :", detect_low_variance_columns(df))
        missing = df.isnull().mean().sort_values(ascending=False)
        st.write("ğŸ”¸ Valeurs manquantes :", missing[missing > 0])

    # -------------------------------------------------------------------------
    # Onglet 6 : Nettoyage manuel
    # -------------------------------------------------------------------------
    with tab6:
        st.markdown("### ğŸ§¼ Nettoyage manuel")
        if st.button("ğŸ” Supprimer les doublons"):
            initial_len = len(df)
            df = df.drop_duplicates()
            removed = initial_len - len(df)
            st.session_state.df = df
            log_transformation(f"{removed} doublons supprimÃ©s.")
            st.success(f"{removed} doublons supprimÃ©s.")

        cols_to_drop = st.multiselect("Colonnes Ã  supprimer", df.columns.tolist())
        if cols_to_drop and st.button("ğŸ—‘ï¸ Supprimer les colonnes sÃ©lectionnÃ©es"):
            df.drop(columns=cols_to_drop, inplace=True)
            log_transformation(f"Colonnes supprimÃ©es manuellement : {', '.join(cols_to_drop)}")
            st.session_state.df = df
            st.success("Colonnes supprimÃ©es.")

    # -------------------------------------------------------------------------
    # Onglet 7 : Statistiques descriptives avancÃ©es
    # -------------------------------------------------------------------------
    with tab7:
        st.markdown("### ğŸ“ Statistiques descriptives avancÃ©es")

        st.info("Affiche les statistiques classiques (moyenne, Ã©cart-typeâ€¦) et avancÃ©es (skewness, kurtosis).")

        # Colonnes numÃ©riques dÃ©tectÃ©es automatiquement
        num_cols = df.select_dtypes(include="number").columns.tolist()

        if not num_cols:
            st.warning("âš ï¸ Aucune variable numÃ©rique dÃ©tectÃ©e.")
            st.stop()

        # Option : analyse groupÃ©e par une variable catÃ©gorielle
        group_by = st.selectbox("ğŸ” Grouper par (optionnel)", [None] + df.select_dtypes(include=["object", "category"]).columns.tolist())

        if group_by:
            # Calcul des statistiques groupÃ©es
            desc_stats = df.groupby(group_by)[num_cols].agg(["mean", "median", "std", "min", "max", "skew", "kurt"])
            # Aplatir les colonnes multi-index
            desc_stats.columns = ['_'.join(col).strip() for col in desc_stats.columns.values]
            st.dataframe(desc_stats, use_container_width=True)
        else:
            # Statistiques globales sur les colonnes numÃ©riques
            desc_stats = df[num_cols].agg(["mean", "median", "std", "min", "max", "skew", "kurt"]).T
            desc_stats.columns = ["Moyenne", "MÃ©diane", "Ã‰cart-type", "Min", "Max", "Skewness", "Kurtosis"]
            st.dataframe(desc_stats, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 8 : CorrÃ©lation avancÃ©e
    # -------------------------------------------------------------------------
    with tab8:
        st.markdown("### ğŸ§¬ CorrÃ©lation avancÃ©e entre variables numÃ©riques")
        st.info("ğŸ“Œ Analyse des dÃ©pendances linÃ©aires et non-linÃ©aires entre variables numÃ©riques.")

        # SÃ©lection du type de corrÃ©lation Ã  afficher
        method = st.radio("ğŸ“ MÃ©thode de corrÃ©lation :", ["pearson", "spearman", "kendall"], horizontal=True)

        # Slider pour appliquer un seuil minimal d'affichage
        threshold = st.slider("ğŸšï¸ Seuil de corrÃ©lation absolue minimale", 0.0, 1.0, 0.3, 0.05)

        # SÃ©lection des colonnes numÃ©riques uniquement
        numeric_cols = df.select_dtypes(include=["number"]).columns

        if len(numeric_cols) < 2:
            st.warning("âš ï¸ Pas assez de variables numÃ©riques pour afficher une matrice de corrÃ©lation.")
        else:
            # Calcul de la matrice de corrÃ©lation avec la mÃ©thode choisie
            corr_matrix = df[numeric_cols].corr(method=method)

            # CrÃ©ation d'une version aplatie de la matrice (utile pour filtrer)
            corr_pairs = (
                corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
                .stack()
                .reset_index()
            )
            corr_pairs.columns = ["Variable 1", "Variable 2", "CorrÃ©lation"]

            # Filtrage selon le seuil choisi
            filtered_corr = corr_pairs[abs(corr_pairs["CorrÃ©lation"]) >= threshold]
            filtered_corr = filtered_corr.sort_values("CorrÃ©lation", ascending=False)

            st.markdown("#### ğŸ“‹ Paires de variables corrÃ©lÃ©es")
            st.dataframe(filtered_corr, use_container_width=True)

            # Heatmap interactive (optionnelle)
            st.markdown("#### ğŸŒ¡ï¸ Heatmap de la matrice de corrÃ©lation")
            fig = px.imshow(
                corr_matrix,
                text_auto=".2f",
                color_continuous_scale="RdBu_r",
                zmin=-1,
                zmax=1,
                aspect="auto",
                title=f"Matrice de corrÃ©lation ({method})"
            )
            st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# ğŸ“Š 3. Analyse des variables catÃ©gorielles
# =============================================================================

elif section == "ğŸ“Š Analyse catÃ©gorielle" and uploaded_file:
    # Chargement du DataFrame
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("ğŸ“Š Analyse des variables catÃ©gorielles")

    # DÃ©tection automatique des colonnes catÃ©gorielles
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    if not cat_cols:
        st.warning("âš ï¸ Aucune variable catÃ©gorielle dÃ©tectÃ©e dans le dataset.")
        st.stop()

    # CrÃ©ation des onglets
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“‹ AperÃ§u global",
        "ğŸ“Š Barplots",
        "ğŸ“ˆ FrÃ©quences cumulÃ©es",
        "ğŸ’¡ Suggestions d'encodage"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 : AperÃ§u global des colonnes catÃ©gorielles
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### ğŸ“‹ DÃ©tail des variables catÃ©gorielles")
        st.info("Nombre de modalitÃ©s uniques, modalitÃ© la plus frÃ©quente et taux de valeurs manquantes.")

        summary_cat = pd.DataFrame({
            "Colonne": cat_cols,
            "Nb modalitÃ©s uniques": [df[col].nunique() for col in cat_cols],
            "ModalitÃ© la + frÃ©quente": [df[col].mode()[0] if not df[col].mode().empty else "â€”" for col in cat_cols],
            "Valeurs manquantes (%)": [f"{df[col].isna().mean() * 100:.1f} %" for col in cat_cols]
        })

        st.dataframe(summary_cat, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 2 : Barplots des top modalitÃ©s
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### ğŸ“Š Distribution des modalitÃ©s (Top N)")
        selected_col = st.selectbox("ğŸ“Œ Choisissez une variable catÃ©gorielle", cat_cols, key="cat_barplot")
        top_n = st.slider("ğŸ”¢ Nombre de modalitÃ©s Ã  afficher", 3, 30, 10)

        top_modalities = (
            df[selected_col]
            .value_counts()
            .head(top_n)
            .reset_index()
        )
        top_modalities.columns = ["ModalitÃ©", "FrÃ©quence"]

        fig = px.bar(
            top_modalities,
            x="ModalitÃ©",
            y="FrÃ©quence",
            title=f"Top {top_n} modalitÃ©s â€“ {selected_col}",
            text="FrÃ©quence"
        )
        st.plotly_chart(fig, use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 : FrÃ©quences relatives et cumulÃ©es
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### ğŸ“ˆ FrÃ©quences relatives et cumulÃ©es")
        selected_col = st.selectbox("ğŸ“Š Variable catÃ©gorielle Ã  analyser", cat_cols, key="cat_freq")

        # Calcul des frÃ©quences relatives
        freq_df = df[selected_col].value_counts(normalize=True).reset_index()

        # Renommage des colonnes pour correspondre Ã  celles appelÃ©es ensuite
        freq_df.columns = ["ModalitÃ©", "FrÃ©quence"]

        # Calcul des frÃ©quences cumulÃ©es
        freq_df["FrÃ©quence cumulÃ©e"] = freq_df["FrÃ©quence"].cumsum()
        freq_df["% FrÃ©quence"] = (freq_df["FrÃ©quence"] * 100).round(2).astype(str) + " %"
        freq_df["% CumulÃ©e"] = (freq_df["FrÃ©quence cumulÃ©e"] * 100).round(2).astype(str) + " %"

        # Affichage du tableau final avec les bonnes colonnes
        st.dataframe(freq_df[["ModalitÃ©", "% FrÃ©quence", "% CumulÃ©e"]], use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : Suggestions dâ€™encodage selon la cardinalitÃ©
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### ğŸ’¡ Suggestions d'encodage automatique")
        st.info("Encodage recommandÃ© en fonction du nombre de modalitÃ©s uniques par colonne.")

        seuil_card = st.slider("ğŸ”§ Seuil max pour OneHot encoding (nb modalitÃ©s)", 2, 50, 10)

        suggestions = []
        for col in cat_cols:
            nb_modal = df[col].nunique()
            if nb_modal <= seuil_card:
                suggestion = "OneHot"
            elif nb_modal == 2:
                suggestion = "Binaire"
            elif nb_modal > seuil_card:
                suggestion = "Ordinal / Embedding"
            else:
                suggestion = "Ã€ vÃ©rifier"

            suggestions.append((col, nb_modal, suggestion))

        suggestion_df = pd.DataFrame(suggestions, columns=["Colonne", "Nb modalitÃ©s", "Encodage suggÃ©rÃ©"])
        st.dataframe(suggestion_df.sort_values("Nb modalitÃ©s"), use_container_width=True)

# =============================================================================
# ğŸš¨ 4. DÃ©tection de problÃ¨mes de qualitÃ© de donnÃ©es
# =============================================================================

elif section == "ğŸš¨ QualitÃ© des donnÃ©es" and uploaded_file:
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("ğŸš¨ ProblÃ¨mes potentiels de qualitÃ© des donnÃ©es")

    # -------------------------------------------------------------------------
    st.markdown("### ğŸ” Colonnes mal typÃ©es")
    suspect_numeric_as_str = [
        col for col in df.select_dtypes(include="object")
        if df[col].str.replace(".", "", regex=False).str.replace(",", "", regex=False).str.isnumeric().mean() > 0.8
    ]
    if suspect_numeric_as_str:
        st.warning(f"ğŸ“Œ Ces colonnes semblent contenir des valeurs numÃ©riques mais sont typÃ©es comme 'object' :")
        st.code(", ".join(suspect_numeric_as_str))
    else:
        st.success("âœ… Aucun champ suspect dÃ©tectÃ© parmi les variables 'object'.")

    # -------------------------------------------------------------------------
    st.markdown("### ğŸ“› Noms suspects ou non normalisÃ©s")
    suspect_names = [col for col in df.columns if col.startswith("Unnamed") or "id" in col.lower()]
    if suspect_names:
        st.warning("âš ï¸ Colonnes avec noms suspects :")
        st.code(", ".join(suspect_names))
    else:
        st.success("âœ… Aucun nom de colonne suspect dÃ©tectÃ©.")

    # -------------------------------------------------------------------------
    st.markdown("### ğŸ§© Valeurs suspectes ou placeholders")
    placeholder_values = ["unknown", "n/a", "na", "undefined", "None", "missing", "?"]
    placeholder_hits = {}
    for col in df.columns:
        hits = df[col].astype(str).str.lower().isin(placeholder_values).sum()
        if hits > 0:
            placeholder_hits[col] = hits
    if placeholder_hits:
        st.warning("ğŸ” Valeurs suspectes trouvÃ©es (placeholders) :")
        st.write(pd.DataFrame.from_dict(placeholder_hits, orient="index", columns=["Occurrences"]))
    else:
        st.success("âœ… Aucune valeur placeholder dÃ©tectÃ©e.")

    # -------------------------------------------------------------------------
    st.markdown("### ğŸ§ª Valeurs extrÃªmes (Z-score simplifiÃ©)")
    import numpy as np
    from scipy.stats import zscore

    num_cols = df.select_dtypes(include="number").columns
    z_outlier_summary = {}
    for col in num_cols:
        if df[col].dropna().std() == 0:
            continue
        z_scores = np.abs(zscore(df[col].dropna()))
        outliers = (z_scores > 3).sum()
        if outliers > 0:
            z_outlier_summary[col] = outliers
    if z_outlier_summary:
        st.warning("ğŸš¨ Valeurs extrÃªmes dÃ©tectÃ©es (Z-score > 3) :")
        st.write(pd.DataFrame.from_dict(z_outlier_summary, orient="index", columns=["Nb outliers"]))
    else:
        st.success("âœ… Pas de valeurs extrÃªmes dÃ©tectÃ©es via Z-score.")

    # -------------------------------------------------------------------------
    st.markdown("### ğŸ“Œ Colonnes uniques / constantes")
    const_cols = detect_constant_columns(df)
    if const_cols:
        st.warning(f"âš ï¸ Colonnes constantes dÃ©tectÃ©es ({len(const_cols)}) :")
        st.code(", ".join(const_cols))
    else:
        st.success("âœ… Aucune colonne constante dÃ©tectÃ©e.")

# =============================================================================
# ğŸ§ª 5. Analyse multivariÃ©e et interactions
# =============================================================================

elif section == "ğŸ§ª Analyse multivariÃ©e" and uploaded_file:
    if "df" not in st.session_state:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("ğŸ§ª Analyse multivariÃ©e et interactions")

    # SÃ©paration des types de variables
    num_cols = df.select_dtypes(include="number").columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    tab1, tab2, tab3 = st.tabs([
        "ğŸ“‰ ACP (PCA)",
        "ğŸ“Š Interactions num â†” cat",
        "ğŸ“š CorrÃ©lation catÃ©gorielle"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 â€“ ACP sur les variables numÃ©riques
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### ğŸ“‰ Analyse en Composantes Principales (ACP / PCA)")
        st.info("Permet de rÃ©duire les dimensions tout en conservant un maximum d'information.")

        if len(num_cols) < 2:
            st.warning("âš ï¸ Pas assez de variables numÃ©riques pour l'ACP.")
        else:
            from sklearn.preprocessing import StandardScaler
            from sklearn.decomposition import PCA
            import plotly.express as px

            df_scaled = StandardScaler().fit_transform(df[num_cols].dropna())

            n_comp = st.slider("Nombre de composantes", 2, min(10, len(num_cols)), 2)
            pca = PCA(n_components=n_comp)
            components = pca.fit_transform(df_scaled)

            pca_df = pd.DataFrame(components, columns=[f"PC{i+1}" for i in range(n_comp)])

            # Option de colorisation par catÃ©gorie
            color_cat = st.selectbox("Colorer par (optionnel)", [None] + cat_cols)
            if color_cat:
                pca_df[color_cat] = df[cat_cols][color_cat]

            # Graphique 2D
            st.markdown("#### ğŸŒˆ Projection des donnÃ©es (PC1 vs PC2)")
            fig = px.scatter(pca_df, x="PC1", y="PC2", color=color_cat if color_cat else None)
            st.plotly_chart(fig, use_container_width=True)

            # Variance expliquÃ©e
            explained = pd.DataFrame({
                "Composante": [f"PC{i+1}" for i in range(len(pca.explained_variance_ratio_))],
                "Variance expliquÃ©e (%)": (pca.explained_variance_ratio_ * 100).round(2)
            })
            st.markdown("#### ğŸ“ˆ Variance expliquÃ©e par composante")
            st.dataframe(explained)

    # -------------------------------------------------------------------------
    # Onglet 2 â€“ Num â†” Cat : boxplot et swarmplot
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### ğŸ§® Analyse croisÃ©e numÃ©rique / catÃ©gorielle")

        if not cat_cols or not num_cols:
            st.warning("âš ï¸ Il faut au moins une variable catÃ©gorielle et une numÃ©rique.")
        else:
            cat_var = st.selectbox("Variable catÃ©gorielle", cat_cols, key="cat_group")
            num_var = st.selectbox("Variable numÃ©rique", num_cols, key="num_group")

            st.plotly_chart(px.box(df, x=cat_var, y=num_var, title="Boxplot croisÃ©"), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 â€“ CorrÃ©lations entre variables catÃ©gorielles
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### ğŸ“š CorrÃ©lations entre variables catÃ©gorielles (CramÃ©r's V)")
        st.info("Mesure la force de l'association entre deux variables catÃ©gorielles.")

        if len(cat_cols) < 2:
            st.warning("âš ï¸ Pas assez de colonnes catÃ©gorielles pour le calcul de CramÃ©r's V.")
        else:
            import numpy as np
            import seaborn as sns
            import matplotlib.pyplot as plt
            from scipy.stats import chi2_contingency

            def cramers_v(x, y):
                confusion_matrix = pd.crosstab(x, y)
                chi2 = chi2_contingency(confusion_matrix)[0]
                n = confusion_matrix.sum().sum()
                phi2 = chi2 / n
                r, k = confusion_matrix.shape
                phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))
                rcorr = r - ((r-1)**2)/(n-1)
                kcorr = k - ((k-1)**2)/(n-1)
                return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))

            matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)
            for col1 in cat_cols:
                for col2 in cat_cols:
                    if col1 == col2:
                        matrix.loc[col1, col2] = 1.0
                    else:
                        matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])
            matrix = matrix.astype(float)

            st.markdown("#### ğŸ”¥ Matrice de CramÃ©r's V")
            fig = px.imshow(matrix, text_auto=".2f", aspect="auto", color_continuous_scale="OrRd")
            st.plotly_chart(fig, use_container_width=True)

# =============================================================================
# ğŸ¯ 6. Analyse orientÃ©e cible
# =============================================================================

elif section == "ğŸ¯ Analyse variable cible" and uploaded_file:
    # On rÃ©cupÃ¨re le DataFrame nettoyÃ© depuis la session s'il existe, sinon on le recharge.
    if "df" not in st.session_state:
        # ATTENTIONâ€¯: ici, le chargement est simplifiÃ© pour un fichier CSV.
        # Pour d'autres formats, il faut adapter la lecture (cf. section Chargement).
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
    else:
        df = st.session_state.df

    st.subheader("ğŸ¯ Analyse orientÃ©e variable cible")

    # DÃ©tection des variables numÃ©riques et catÃ©gorielles
    num_cols = df.select_dtypes(include=["number"]).columns.tolist()
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()

    if not num_cols:
        st.warning("âš ï¸ Aucune variable numÃ©rique dÃ©tectÃ©e.")
        st.stop()

    # SÃ©lection de la variable cible principale et optionnelle
    target_1 = st.selectbox("ğŸ¯ Variable cible principale", num_cols, key="target1")
    target_2 = st.selectbox("ğŸ¯ Variable cible secondaire (optionnel)", [None] + num_cols, key="target2")

    # CrÃ©ation des onglets pour l'analyse de la variable cible
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š CorrÃ©lations",
        "ğŸ“ˆ Cible par groupe",
        "ğŸ“¦ Boxplot",
        "ğŸ§® Nuage de points"
    ])

    # -------------------------------------------------------------------------
    # Onglet 1 : CorrÃ©lations
    # -------------------------------------------------------------------------
    with tab1:
        st.markdown("### ğŸ“Š CorrÃ©lations avec la variable cible")
        st.info("CorrÃ©lations linÃ©aires (Pearson) avec la variable cible principale.")
        corr = df.select_dtypes(include=["number"]).corr()[target_1].drop(target_1).sort_values(ascending=False)
        st.dataframe(corr)
        st.plotly_chart(px.bar(corr.reset_index(), x="index", y=target_1), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 2 : Analyse de la cible par groupe
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("### ğŸ“ˆ Moyenne de la cible par groupe")
        group_col = st.selectbox("Variable catÃ©gorielle", cat_cols, key="groupcol")
        avg_target1 = df.groupby(group_col)[target_1].mean().sort_values(ascending=False).reset_index()
        st.plotly_chart(px.bar(avg_target1, x=group_col, y=target_1), use_container_width=True)

        if target_2:
            avg_target2 = df.groupby(group_col)[target_2].mean().sort_values(ascending=False).reset_index()
            st.plotly_chart(px.bar(avg_target2, x=group_col, y=target_2), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 3 : Boxplot interactif
    # -------------------------------------------------------------------------
    with tab3:
        st.markdown("### ğŸ“¦ Boxplot interactif")
        cat_col = st.selectbox("X = variable catÃ©gorielle", cat_cols, key="box_cat")
        num_col = st.selectbox("Y = variable numÃ©rique", num_cols, key="box_num")
        st.plotly_chart(px.box(df, x=cat_col, y=num_col), use_container_width=True)

    # -------------------------------------------------------------------------
    # Onglet 4 : Scatter Plot (nuage de points)
    # -------------------------------------------------------------------------
    with tab4:
        st.markdown("### ğŸ§® Scatter Plot")
        x = st.selectbox("X", num_cols, key="xscatter")
        y = st.selectbox("Y", num_cols, key="yscatter")
        color = st.selectbox("Couleur (optionnelle)", [None] + cat_cols, key="color_scatter")
        st.plotly_chart(px.scatter(df, x=x, y=y, color=color), use_container_width=True)

# =============================================================================
# ğŸ’¾ 4. Export
# =============================================================================

elif section == "ğŸ’¾ Export" and uploaded_file:
    # RÃ©cupÃ©ration du DataFrame nettoyÃ© depuis la session
    df = st.session_state.get("df")
    if df is not None:
        st.subheader("ğŸ’¾ Export du fichier final")
        with st.form("export_form"):
            file_name = st.text_input("Nom du fichier CSV", value="cleaned_data.csv")
            submit = st.form_submit_button("ğŸ“¥ TÃ©lÃ©charger")
            if submit:
                csv_data = df.to_csv(index=False).encode("utf-8")
                st.download_button("TÃ©lÃ©charger le CSV", csv_data, file_name, mime="text/csv")
    else:
        st.warning("âŒ Aucune donnÃ©e disponible pour lâ€™export.")
