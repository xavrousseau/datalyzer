# ========================================================================
# sections/analyse_explo.py
#
# Ce script utilise Streamlit pour effectuer une analyse exploratoire
# sur un DataFrame. Il met en place plusieurs onglets pour visualiser :
# - Les types et caractÃ©ristiques des colonnes
# - Les donnÃ©es manquantes
# - Les distributions des variables
# - La dÃ©tection d'outliers
# - Les statistiques descriptives
# - Des opÃ©rations de nettoyage automatique
# - Les corrÃ©lations entre variables
#
# Des utilitaires personnalisÃ©s sont importÃ©s pour faciliter l'EDA, la journalisation
# des transformations et la sauvegarde de snapshots du dataset.
# ========================================================================

import streamlit as st         # Permet de crÃ©er des applications web interactives pour l'analyse de donnÃ©es.
import pandas as pd            # Librairie de manipulation et d'analyse de donnÃ©es.
import plotly.express as px    # Librairie de visualisations graphiques interactives.

# Importation des fonctions utilitaires pour l'analyse exploratoire depuis le module utils.eda_utils.
from utils.eda_utils import (
    detect_constant_columns,       # Renvoie les colonnes du DataFrame qui n'ont qu'une seule valeur.
    detect_low_variance_columns,     # Renvoie les colonnes prÃ©sentant une faible variance, potentiellement non informatives.
    detect_outliers_iqr,             # DÃ©tecte les valeurs aberrantes (outliers) en utilisant la mÃ©thode de l'IQR.
    get_columns_above_threshold,     # Retourne les colonnes dont le pourcentage de valeurs manquantes dÃ©passe un seuil donnÃ©.
    drop_missing_columns,            # Fonction pour supprimer les colonnes avec trop de valeurs manquantes.
    plot_missing_values              # GÃ©nÃ¨re un graphique interactif montrant la rÃ©partition des valeurs manquantes.
)

# Importation des fonctions de log et de sauvegarde des snapshots pour tracer les transformations du dataset.
from utils.log_utils import log_transformation   # Journalise les transformations appliquÃ©es sur le dataset.
from utils.snapshot_utils import save_snapshot     # Sauvegarde un instantanÃ© (snapshot) du dataset ou d'Ã©tapes clÃ©s.

# ----------------------------------------------------------------------------
# Fonction utilitaire : rÃ©sumÃ© synthÃ©tique dâ€™un DataFrame
# CrÃ©e un rÃ©sumÃ© prÃ©sentant, pour chaque colonne, son nom, son type, le nombre
# de valeurs uniques et un exemple de valeur non nulle.
# ----------------------------------------------------------------------------
def summarize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    return pd.DataFrame({
        "Colonne": df.columns,
        "Type pandas": df.dtypes.astype(str),
        "Nb valeurs uniques": df.nunique(),
        "Exemple": [
            df[col].dropna().astype(str).unique()[0] if df[col].dropna().shape[0] > 0 else "â€”"
            for col in df.columns
        ]
    })

# ----------------------------------------------------------------------------
# Fonction pour marquer une Ã©tape comme validÃ©e et sauvegarder un snapshot
# Cette fonction met Ã  jour l'Ã©tat de session de Streamlit, sauvegarde un snapshot
# et affiche un message de succÃ¨s.
# ----------------------------------------------------------------------------
def mark_step_done(step: str, custom_name: str = None):
    if "validation_steps" not in st.session_state:
        st.session_state["validation_steps"] = {}
    # Marque l'Ã©tape comme validÃ©e dans la session
    st.session_state["validation_steps"][step] = True
    # Utilise le nom personnalisÃ© pour le snapshot si fourni, sinon gÃ©nÃ¨re un nom par dÃ©faut
    label = custom_name if custom_name else f"{step}_validated"
    # Sauvegarde un snapshot avec le label dÃ©fini
    save_snapshot(label=label)
    st.success("âœ… Ã‰tape validÃ©e. Snapshot sauvegardÃ©.")

# ----------------------------------------------------------------------------
# Bouton de validation avec champ optionnel pour le nom du snapshot.
# Affiche un champ de saisie et un bouton, puis valide l'Ã©tape si le bouton est cliquÃ©.
# ----------------------------------------------------------------------------
def validate_step_button(step_name: str, label: str = "âœ… Valider lâ€™Ã©tape"):
    # Permet de saisir un nom personnalisÃ© pour le snapshot (optionnel)
    name = st.text_input(f"Nom du snapshot pour l'Ã©tape `{step_name}` (optionnel)", key=f"name_{step_name}")
    # Bouton de validation qui, lorsqu'il est cliquÃ©, valide l'Ã©tape via la fonction mark_step_done.
    if st.button(label, key=f"step_{step_name}"):
        mark_step_done(step_name, custom_name=name)

# ----------------------------------------------------------------------------
# Fonction principale pour lancer l'analyse exploratoire
# Elle organise l'affichage de plusieurs onglets, chacun dÃ©diÃ© Ã  une facette de l'EDA.
# ----------------------------------------------------------------------------
def run_analyse_exploratoire(df):
    # Affiche un sous-titre pour la section d'analyse exploratoire
    st.subheader("ğŸ” Analyse exploratoire")

    # DÃ©finition des Ã©tapes de l'analyse avec un label court pour chaque section
    steps = {
        "types": "ğŸ§¾ Types",
        "missing": "â“ Manquants",
        "histos": "ğŸ“Š Distributions",
        "outliers": "ğŸš¨ Outliers",
        "stats": "ğŸ“ˆ Stats",
        "cleaning": "ğŸ§¹ Nettoyage",
        "correlations": "ğŸ”— CorrÃ©lations"
    }

    # Bandeau latÃ©ral affichant la progression (Ã©tapes validÃ©es ou non)
    st.sidebar.markdown("### ğŸ—‚ï¸ Progression")
    for key, label in steps.items():
        status = "âœ…" if st.session_state.get("validation_steps", {}).get(key) else "â¬œ"
        st.sidebar.write(f"{status} {label}")

    # CrÃ©ation d'un ensemble d'onglets pour chaque Ã©tape
    tabs = st.tabs(list(steps.values()))

    # ================================================
    # Onglet 1 â€” Types de colonnes
    # ================================================
    with tabs[0]:
        st.markdown("### ğŸ§¬ Vue d'ensemble des types de colonnes")
        st.markdown("""
        Cet onglet permet dâ€™**inspecter chaque colonne du dataset** :
        - Son type (`int`, `float`, `object`, etc.),
        - Son nombre de valeurs uniques,
        - Un exemple de valeur prÃ©sente.
        
        Cela aide Ã  dÃ©tecter rapidement des colonnes suspectes, comme des identifiants ou des colonnes constantes.
        """)
        # GÃ©nÃ¨re un rÃ©sumÃ© synthÃ©tique du DataFrame
        summary = summarize_dataframe(df)
        st.dataframe(summary, use_container_width=True)
        # Affiche un rÃ©sumÃ© global du nombre de colonnes et des colonnes constantes
        st.markdown(f"""
        - Total de colonnes : **{df.shape[1]}**
        - Colonnes constantes (1 seule valeur) : **{(summary['Nb valeurs uniques'] <= 1).sum()}**
        """)
        # Bouton de validation de cette Ã©tape
        validate_step_button("types")

    # ================================================
    # Onglet 2 â€” DonnÃ©es manquantes
    # ================================================
    with tabs[1]:
        st.markdown("### ğŸ“‰ Analyse des valeurs manquantes")
        st.markdown("""
        Visualisez les colonnes ayant des valeurs manquantes :
        - Ajustez un **seuil (%)** pour dÃ©terminer quelles colonnes supprimer.
        - Choisissez manuellement ou automatiquement les colonnes Ã  supprimer.
        """)
        # Disposition en deux colonnes pour ajuster le seuil et le nombre d'affichage
        c1, c2 = st.columns(2)
        with c1:
            seuil_pct = st.slider("ğŸ¯ Seuil de valeurs manquantes (%)", 0, 100, 20)
        with c2:
            top_n = st.slider("ğŸ”¢ Colonnes Ã  afficher", 5, 50, 15)
        # Convertit le seuil en proportion (0 Ã  1)
        seuil = seuil_pct / 100
        # GÃ©nÃ¨re et affiche un graphique interactif des valeurs manquantes
        fig = plot_missing_values(df, seuil=seuil, top_n=top_n)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("âœ… Aucune valeur manquante dÃ©tectÃ©e.")
        # DÃ©termine quelles colonnes dÃ©passent le seuil de valeurs manquantes
        cols_to_remove = get_columns_above_threshold(df, seuil)
        if cols_to_remove:
            st.warning(f"{len(cols_to_remove)} colonnes dÃ©passent le seuil de {seuil_pct}%")
            # Permet Ã  l'utilisateur de sÃ©lectionner les colonnes Ã  supprimer
            selected = st.multiselect("Colonnes Ã  supprimer", cols_to_remove, default=cols_to_remove)
            if st.button("ğŸ—‘ï¸ Supprimer sÃ©lection", key="drop_missing"):
                df.drop(columns=selected, inplace=True)
                st.session_state.df = df  # Met Ã  jour le DataFrame dans l'Ã©tat de session
                log_transformation(f"{len(selected)} colonnes supprimÃ©es pour valeurs manquantes")
                save_snapshot("missing_dropped")
                st.success("âœ… Suppression effectuÃ©e.")
        else:
            st.info("Aucune colonne ne dÃ©passe le seuil.")
        # Bouton de validation de l'Ã©tape "missing"
        validate_step_button("missing")

    # ================================================
    # Onglet 3 â€” Distributions
    # ================================================
    with tabs[2]:
        st.markdown("### ğŸ“Š Histogrammes")
        st.markdown("Visualisez la distribution d'une variable numÃ©rique pour dÃ©tecter les asymÃ©tries, pics ou valeurs extrÃªmes.")
        # Extraction des colonnes numÃ©riques du DataFrame
        num_cols = df.select_dtypes(include="number").columns.tolist()
        if not num_cols:
            st.warning("Aucune variable numÃ©rique.")
        else:
            # Permet Ã  l'utilisateur de choisir une variable numÃ©rique Ã  visualiser
            col = st.selectbox("Variable Ã  visualiser", num_cols)
            # CrÃ©e un histogramme interactif avec Plotly Express
            fig = px.histogram(df, x=col, nbins=50)
            st.plotly_chart(fig, use_container_width=True)
            # Calcule et affiche l'asymÃ©trie de la distribution
            skew = df[col].skew()
            direction = "symÃ©trique" if abs(skew) < 0.5 else (
                "asymÃ©trique positive" if skew > 0 else "asymÃ©trique nÃ©gative"
            )
            st.markdown(f"**AsymÃ©trie :** `{skew:.2f}` â†’ **{direction}**")
        # Bouton de validation de l'Ã©tape "histos"
        validate_step_button("histos")

    # ================================================
    # Onglet 4 â€” Outliers
    # ================================================
    with tabs[3]:
        st.markdown("### ğŸš¨ DÃ©tection des valeurs aberrantes")
        st.markdown("RepÃ©rez les outliers Ã  l'aide de la mÃ©thode IQR (Interquartile Range).")
        # Permet de sÃ©lectionner une variable pour la dÃ©tection des outliers
        col = st.selectbox("Variable Ã  analyser", num_cols, key="iqr_col")
        # Utilise la fonction dÃ©diÃ©e pour dÃ©tecter les outliers
        outliers = detect_outliers_iqr(df, col)
        st.info(f"{len(outliers)} outliers dÃ©tectÃ©s sur `{col}`")
        st.dataframe(outliers, use_container_width=True)
        # Bouton de validation de l'Ã©tape "outliers"
        validate_step_button("outliers")

    # ================================================
    # Onglet 5 â€” Statistiques descriptives
    # ================================================
    with tabs[4]:
        st.markdown("### ğŸ“ˆ Statistiques descriptives")
        # Calcule et affiche les statistiques descriptives du DataFrame
        stats = df.describe().T
        st.dataframe(stats, use_container_width=True)
        # Estime le pourcentage de valeurs manquantes globales
        n, p = stats.shape[0], df.shape[0]
        pct_missing = 100 - stats["count"].sum() / (n * p) * 100
        st.info(f"{n} variables numÃ©riques â€¢ Estimation de valeurs manquantes : **{pct_missing:.2f}%**")
        # Bouton de validation de l'Ã©tape "stats"
        validate_step_button("stats")

    # ================================================
    # Onglet 6 â€” Nettoyage automatique
    # ================================================
    with tabs[5]:
        st.markdown("### ğŸ§¹ Nettoyage automatique")
        # DÃ©tecte et affiche les colonnes constantes
        const_cols = detect_constant_columns(df)
        if const_cols:
            st.warning(f"{len(const_cols)} colonnes constantes dÃ©tectÃ©es")
            if st.button("âŒ Supprimer constantes"):
                df.drop(columns=const_cols, inplace=True)
                st.session_state.df = df
                log_transformation(f"Constantes supprimÃ©es : {const_cols}")
                save_snapshot("drop_constants")
        # DÃ©tecte et affiche les colonnes Ã  faible variance
        low_var = detect_low_variance_columns(df)
        if low_var:
            st.warning(f"{len(low_var)} colonnes Ã  faible variance dÃ©tectÃ©es")
            if st.button("âŒ Supprimer faible variance"):
                df.drop(columns=low_var, inplace=True)
                st.session_state.df = df
                log_transformation(f"Faible variance supprimÃ©es : {low_var}")
                save_snapshot("drop_low_var")
        # Suppression des doublons : l'utilisateur peut sÃ©lectionner les colonnes Ã  utiliser
        st.markdown("#### ğŸ” Suppression de doublons")
        sel_cols = st.multiselect("Colonnes Ã  utiliser pour l'identification des doublons", df.columns.tolist())
        dupes = df[df.duplicated(subset=sel_cols or None, keep=False)]
        if not dupes.empty:
            st.warning(f"{len(dupes)} doublons dÃ©tectÃ©s")
            if st.checkbox("Afficher doublons"):
                st.dataframe(dupes)
            if st.button("ğŸ—‘ï¸ Supprimer doublons"):
                df.drop_duplicates(subset=sel_cols or None, inplace=True)
                st.session_state.df = df
                save_snapshot("drop_duplicates")
                st.success("âœ… Doublons supprimÃ©s.")
        else:
            st.success("âœ… Aucun doublon dÃ©tectÃ©")
        # Bouton de validation de l'Ã©tape "cleaning"
        validate_step_button("cleaning")

    # ================================================
    # Onglet 7 â€” CorrÃ©lations entre variables numÃ©riques
    # ================================================
    with tabs[6]:
        st.markdown("### ğŸ”— CorrÃ©lations entre variables numÃ©riques")
        st.markdown("""
        Cette matrice permet dâ€™**Ã©valuer les relations linÃ©aires** entre variables numÃ©riques.
        - Aide Ã  dÃ©tecter les redondances (variables fortement corrÃ©lÃ©es).
        - Met en avant des relations intÃ©ressantes pour la modÃ©lisation.
        - Les valeurs proches de +1 ou -1 indiquent une forte corrÃ©lation.
        """)
        # SÃ©lection de la mÃ©thode de corrÃ©lation (Pearson, Spearman, Kendall) via radio button
        method = st.radio("ğŸ“ MÃ©thode de corrÃ©lation :", ["pearson", "spearman", "kendall"], horizontal=True)
        # RÃ©cupÃ¨re les colonnes numÃ©riques du DataFrame
        num_cols = df.select_dtypes(include="number").columns
        if len(num_cols) < 2:
            st.warning("âš ï¸ Pas assez de variables numÃ©riques pour une matrice de corrÃ©lation.")
        else:
            # Calcule la matrice de corrÃ©lation et l'affiche en utilisant Plotly Express pour une visualisation interactive
            corr = df[num_cols].corr(method=method)
            fig = px.imshow(
                corr,
                text_auto=".2f",
                aspect="auto",
                color_continuous_scale="RdBu_r",
                zmin=-1,
                zmax=1
            )
            # Ajuste la taille du graphique en fonction du nombre de variables
            fig.update_layout(
                width=min(1000, 80 * len(num_cols)),
                height=min(1000, 80 * len(num_cols)),
                xaxis=dict(tickangle=45),
                margin=dict(t=40, l=20, r=20, b=80)
            )
            st.plotly_chart(fig, use_container_width=True)
        # Bouton de validation de l'Ã©tape "correlations"
        validate_step_button("correlations")

    # -----------------------------------------------
    # RÃ©capitulatif global aprÃ¨s nettoyage
    # Affiche un rÃ©sumÃ© synthÃ©tique du DataFrame final Ã  l'aide de summarize_dataframe.
    # -----------------------------------------------
    st.markdown("### ğŸ“„ RÃ©sumÃ© global (aprÃ¨s nettoyage)")
    st.dataframe(summarize_dataframe(df), use_container_width=True)
